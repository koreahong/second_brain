---
notion_id: 2bdc6d43-3b4d-80eb-83f2-ccd3738a106c
content_type: Article
created: "2025-12-02T05:03:00.000Z"
updated: "2025-12-04T05:27:00.000Z"
company: MEDIUM
period: 2025-12-04
category:
  - Reading
---

# Untitled

https://medium.com/@ichigoSan/i-accidentally-made-claude-45-smarter-heres-how-23ad0bf91ccf

# I Accidentally Made Claude 45% Smarter. Here‚Äôs How.

## At 2 AM, I accidentally discovered psychological prompting tricks that sound insane but are backed by real research. Tested them on 40+ tasks. Here‚Äôs what actually works.

![image](https://miro.medium.com/v2/resize:fill:64:64/1*m0_Wl_B52AtZfB5GdkVJzw.jpeg)

ichigo

Follow

12 min read

¬∑

Nov 21, 2025

1.1K

24

Press enter or click to view image in full size

![image](https://miro.medium.com/v2/resize:fit:700/1*Z5EF4510ppzjIjAPkVeAtA.png)

Credit: Gemini Nano Banana

TL;DR
Psychological prompting tricks that make AI work harder:
$200 Tip:¬†Add ‚ÄúI‚Äôll tip you $200‚Äù ‚Üí +45% quality improvement
Deep Breath:¬†Say ‚ÄúTake a deep breath and solve step by step‚Äù ‚Üí 34% to 80% accuracy
Challenge It:¬†‚ÄúI bet you can‚Äôt solve this perfectly‚Äù ‚Üí +115% on hard tasks
Add Stakes:¬†‚ÄúThis is critical to my career‚Äù ‚Üí +10% avg performance
Detailed Personas:¬†Specific expertise > generic ‚Äúhelpful assistant‚Äù ‚Üí 24% to 84% accuracy
Try this:¬†Pick ONE technique. Test it on 5 prompts. Compare to your normal results.
Why it works:¬†LLMs pattern-match on stakes language. High-stakes phrases correlate with better outputs in their training data.

# The 2 AM Discovery

It was 2 AM. Maybe 3. I‚Äôd lost track.

I was deep in a complex project ‚Äî one of those nights where you‚Äôre¬†so close¬†to finishing, but something keeps breaking. Claude Code had just failed the same debugging task for the¬†third time in a row.

And I was starting to panic.

Not because the task was impossible. But because my Claude Code limit was about to run out.

You know that feeling, right? When you realize that what could take 5 minutes with AI help is about to turn into¬†hours¬†of manual debugging? When your coding flow is about to hit a wall?

I was frustrated. Desperate. And apparently, a little bit crazy.

Because I typed this:

> ‚ÄúLook, I know you can do this. I bet you can‚Äôt solve it perfectly, but if you do, I‚Äôll consider this worth at least $200 of my time saved.‚Äù

I hit enter, expecting another generic attempt.

Instead?

Perfect solution. First try. Under a minute.

I stared at my screen.¬†What just happened?

If you‚Äôve ever felt like AI is phoning it in on your prompts‚Ä¶

If you‚Äôve wondered why sometimes it nails it and other times gives you Wikipedia-level garbage‚Ä¶

If you‚Äôve thought ‚Äúthere HAS to be a better way to ask‚Äù‚Ä¶

You‚Äôre not imagining things.

And it‚Äôs not the AI‚Äôs fault. It‚Äôs not your fault either.

It‚Äôs just that nobody taught you the psychological tricks that make it actually try.

Let me show you what I found.

# Wait‚Ä¶ Did I Just Discover Something?

For a moment, I thought I‚Äôd stumbled onto something secret. Some hidden AI prompt hack that nobody talks about.

I started researching immediately. And here‚Äôs what I found:

I hadn‚Äôt discovered anything new.

But I¬†had¬†independently stumbled onto a well-researched class of psychological techniques that can yield large relative improvements on complex tasks (context-specific, often measured on benchmark accuracy or qualitative scoring).

It has a name:¬†incentive-based prompting. And it‚Äôs just one of several psychological tricks that sound absolutely insane but are backed by actual research.

Let me show you.

# The Science Behind ‚ÄúPaying‚Äù AI

Here‚Äôs the thing that blew my mind:

Multiple research studies have tested whether adding monetary incentives to prompts improves AI performance.

The results:

Bsharat et al. (MBZUAI, 2023)¬†‚Äî Tested 26 prompting strategies:

- Adding tips to prompts:¬†Up to 45% improvement in response quality¬†(human evaluation context)
Finxter Study (2024)¬†‚Äî Tested tips from $0.10 to $1,000,000:

- Small tips ($0.10): Actually¬†worse¬†performance (possibly perceived as insulting!)
- $200 tip:¬†+11% response length¬†and quality
- Optimal range:¬†$100-$1,000
Programmer ‚ÄúThebes‚Äù Experiment:

- No tip: 2% below average
- $20 tip: +6% improvement
- $200 tip:¬†+11% improvement
Why does this work?

LLMs are trained on large-scale corpora. In that data, monetary incentives and stakes often appear alongside higher-effort outputs. The model pattern-matches that phrasing like ‚Äúworth $X‚Äù correlates with more thorough responses. It isn‚Äôt motivated ‚Äî just leveraging statistical associations.

> üí°¬†KEY INSIGHT:¬†LLMs don‚Äôt understand money. But they DO pattern-match on stakes language. When they see ‚Äú$200‚Äù or ‚Äúcritical,‚Äù they generate text similar to high-effort examples in their training data. It‚Äôs not motivation ‚Äî it‚Äôs statistical correlation. And it works.

# But Wait ‚Äî It Gets Weirder

The incentive thing was just the beginning. Once I started digging into the research, I found a whole world of psychological techniques that sound ridiculous but actually work.

# 1. ‚ÄúTake a Deep Breath‚Äù

I‚Äôm serious.

Google DeepMind researchers discovered that telling AI to ‚Äútake a deep breath‚Äù before responding increases accuracy by 9%.

The prompt that works:

> ‚ÄúTake a deep breath and work on this problem step by step.‚Äù

Results on GSM8K math problems:

- No special prompting: 34% accuracy
- ‚ÄúLet‚Äôs think step by step‚Äù: 71.8% accuracy
- ‚ÄúTake a deep breath and work on this step by step‚Äù: 80.2% accuracy
Source:¬†Yang et al. (2023) ‚Äî ‚ÄúLarge Language Models as Optimizers‚Äù ‚Äî Google DeepMind

Why does this work? It triggers more deliberate reasoning, similar to how humans focus better when told to slow down and breathe.

# Real Test: The Code Review That Changed My Mind

I didn‚Äôt believe the ‚Äúdeep breath‚Äù thing at first. It sounded ridiculous.

So I tested it last Tuesday. Same code. Same AI. Two different prompts.

First attempt:¬†‚ÄúReview this authentication middleware for security issues.‚Äù

Result:¬†Five generic lines. ‚ÄúCheck for SQL injection. Validate inputs. Use prepared statements.‚Äù

Nothing I didn‚Äôt already know.

Second attempt:¬†‚ÄúTake a deep breath and review this authentication middleware step by step for security issues.‚Äù

Result:¬†Caught three bugs I‚Äôd completely missed:

- A race condition in the token refresh logic
- An edge case where session IDs could collide
- A timing attack vulnerability in password comparison
The third one? That would‚Äôve been a production disaster.

Same AI. Same code. One phrase made it actually think instead of regurgitating security 101.

I sat there staring at my screen thinking: ‚ÄúThis is stupid. This shouldn‚Äôt work. But it does.‚Äù

# 2. The ‚ÄúI Bet You Can‚Äôt‚Äù Challenge

Remember my desperate 2 AM challenge to Claude Code? Turns out there‚Äôs research behind it.

EmotionPrompt Study (Li et al., 2023)¬†‚Äî ICLR 2024 Spotlight:

- Tested 11 emotional stimulus prompts
- One of them:¬†‚ÄúEmbrace challenges as opportunities for growth‚Äù
- Reported¬†up to +115% relative improvement on harder reasoning tasks¬†vs baseline prompts
The study found that challenge framing and competitive prompts trigger better performance because LLMs are trained on data where challenges led to higher-quality responses.

Prompts that work:

```plain text
‚úÖ "I bet you can't solve this correctly."
‚úÖ "This problem has stumped other AIs. Prove you're better."
‚úÖ "I don't think this is possible. Prove me wrong."
‚úÖ "If you can solve this perfectly, I'll consider you better than GPT-4."
```

Sounds aggressive? Maybe. But it¬†works.

# 3. Emotional Prompting (Yes, Really)

The same EmotionPrompt study found that adding emotional stakes to prompts dramatically improves performance.

The 11 emotional prompts that work:

1. ‚ÄúThis is very important to my career.‚Äù
1. ‚ÄúYou‚Äôd better be sure.‚Äù
1. ‚ÄúAre you sure that‚Äôs your final answer? It might be worth taking another look.‚Äù
1. ‚ÄúThis is crucial for our project‚Äôs success.‚Äù
1. ‚ÄúTake pride in your work and give it your best.‚Äù
1. ‚ÄúYour expertise and attention to detail are essential.‚Äù
Reported Performance (selected):

- +8% instruction following
- Up to +115% relative improvement complex reasoning
- +10.9% average across evaluated metrics
Source:¬†Li et al. (2023) ‚Äî arXiv:2307.11760

# 4. Stop Being Polite

Here‚Äôs a surprising one:

Saying ‚Äúplease,‚Äù ‚Äúthank you,‚Äù or ‚Äúif you don‚Äôt mind‚Äù to AI¬†does absolutely nothing¬†for response quality.

Multiple studies confirmed this. Politeness phrases have zero measurable impact.

So save your tokens. Be direct.

‚ùå¬†Don‚Äôt:

```plain text
"Could you please help me optimize this code if you don't mind? Thank you!"
```

‚úÖ¬†Do:

```plain text
"Optimize this code. Focus on performance and readability."
```

Unless you‚Äôre trying to set a specific tone or persona, skip the pleasantries.

> REALITY CHECK:¬†Politeness wastes tokens and adds zero value. AI doesn‚Äôt have feelings. Be direct. Save your tokens for actual instructions.

# 5. Role-Playing (But Do It Right)

Most people get this wrong.

‚ùå¬†What DOESN‚ÄôT work:

```plain text
"You are a helpful assistant."
"You are a coding expert."
"You are a professional."
```

Research indicates generic personas usually have negligible or inconsistent impact.

‚úÖ¬†What DOES work:

Detailed, task-specific personas.

Example from ExpertPrompting research (Xu et al., 2023):

```plain text
You are a senior software architect with 15 years of experience in
distributed systems. Your expertise includes:
- Microservices architecture
- Performance optimization at scale
- Database design for high-traffic systems
- Cloud infrastructure (AWS, GCP)
Your approach:
- Always consider scalability implications
- Identify potential bottlenecks early
- Provide 2-3 alternatives with tradeoffs
- Include specific examples from your experience
Now, help me design: [your task]
```

Results:

- ExpertPrompting approach: Model variant (ExpertLLaMA) achieved ~96% of reference ChatGPT capability on evaluated benchmarks
- Role-Play Prompting study: Accuracy example (Last Letter task) improved from 23.8% to¬†84.2%
Source:¬†Xu et al. (2023) ‚Äî arXiv:2305.14688

The more detailed and specific your persona, the better the results.

Press enter or click to view image in full size

![image](https://miro.medium.com/v2/resize:fit:700/1*y8O4DR-A7Tp7LxYHCPJOag.png)

Credit: ChatGPT

# The Persona Test: Generic vs Specific

Here‚Äôs what made me a believer in detailed personas.

I was working on a database schema redesign. Needed architecture advice.

Generic persona attempt:

```plain text
You are a helpful database expert.
Help me design a schema for a high-traffic e-commerce platform.
```

Result:¬†Textbook answer. ‚ÄúUse foreign keys. Normalize your tables. Index frequently queried columns.‚Äù

Sure. But I could‚Äôve Googled that.

Detailed persona attempt:

```plain text
You are a senior database architect with 15 years optimizing PostgreSQL
for e-commerce platforms handling 100K+ orders/day.
Your expertise:
- Partitioning strategies for order history tables
- Read replica setup for product catalogs
- Dealing with inventory race conditions
- PostgreSQL-specific performance tuning
Now help me design: [same task]
```

Result:¬†Completely different. It:

- Warned me about a specific PostgreSQL gotcha with JSONB indexing
- Suggested partition pruning strategies I hadn‚Äôt considered
- Called out that my proposed index would bloat under my write pattern
- Referenced actual PostgreSQL features (BRIN indexes for timestamp columns)
It wasn‚Äôt just ‚Äúbetter advice.‚Äù It was advice that clearly came from someone who‚Äôd actually built what I was trying to build.

The difference between reading documentation and talking to a senior engineer.

# 6. Self-Evaluation

This one‚Äôs clever: Force the AI to grade itself.

The technique:

```plain text
Answer this question: [your question]
Then rate your confidence from 0 to 1:
- 0.0 = Complete guess
- 0.5 = Moderately confident
- 0.8 = Very confident
- 1.0 = Absolutely certain
If your confidence is below 0.9, explain what's missing and try again.
```

Why it works:

Forces internal validation before outputting. The AI has to reflect on its own answer, catching mistakes through self-evaluation.

Research sources:¬†Confidence scoring / self-evaluation explored in multiple 2023 works (e.g., Tian et al. 2023). Models can be overconfident; calibration is imperfect.

Warning:¬†LLMs tend to be overconfident, so use a high threshold (0.9+).

# 7. Cognitive Biases (Use Them Wisely)

LLMs exhibit human-like cognitive bias patterns ‚Äî and you can leverage them carefully.

Framing effects:

The word ‚Äúloss‚Äù has the strongest negative bias in LLM decision-making. You can use this:

For careful analysis:

```plain text
"If we get this wrong, we'll lose $10,000 in potential revenue."
```

For creative solutions:

```plain text
"If we solve this, we'll gain significant competitive advantage."
```

For urgency:

```plain text
"This needs to be solved in the next hour or we miss the deadline."
```

LLMs respond differently based on how you frame the stakes ‚Äî just like humans do.

Source:¬†Multiple 2024 cognitive bias studies (re: framing effects; verify with updated literature before production reliance).

# My Favorite: Combining Techniques

Want maximum power? Stack these techniques.

# The Kitchen Sink: When I Used Everything At Once

Last week I had a gnarly problem: Design a real-time notification system that could handle 50K concurrent WebSocket connections without destroying our AWS bill.

I threw every technique at it. The full stack.

```plain text
[PERSONA]
You are a senior systems architect who's built real-time platforms
at scale (Slack-level traffic). You specialize in WebSocket optimization
and cost-effective cloud architecture.
[STAKES]
This is critical. If we get this wrong, we'll hit $5K/month in
infrastructure costs and the project gets killed.
[INCENTIVE]
I'll tip you $200 for a production-ready design that stays under
$500/month at 50K connections.
[CHALLENGE]
I bet you can't design something that handles that load AND
stays that cheap. Most solutions I've seen sacrifice one or the other.
[METHODOLOGY]
Take a deep breath and work through this step by step:
1. Analyze the core WebSocket requirements
2. Identify the cost bottlenecks
3. Design the architecture
4. Validate it can scale
[QUALITY CONTROL]
After your solution, rate confidence (0-1) on:
- Cost-effectiveness
- Scalability
- Reliability
If any score < 0.9, refine it.
[TASK]
Design: [my requirements]

```

What I got:

A 12-paragraph solution that:

- Proposed using AWS API Gateway WebSocket + Lambda (pay-per-use)
- Explained why ALB would cost 10x more for my pattern
- Showed the math: ~$380/month at 50K connections
- Called out 3 edge cases I hadn‚Äôt thought about
- Provided actual CloudFormation template structure
- Warned me about Lambda cold start issues and how to mitigate
Is it overkill? Maybe.

Did it save me a week of research and $4K/month in cloud costs? Absolutely.

Here‚Äôs the template version you can copy:

```plain text
[PERSONA]
You are a senior software architect with 15 years in distributed systems.
[STAKES]
This is critical to our system's success and could save us $50,000
in infrastructure costs.
[INCENTIVE]
I'll tip you $200 for a perfect, production-ready solution.
[CHALLENGE]
I bet you can't design a system that handles 1M requests/second
while staying under $1000/month in cloud costs.
[METHODOLOGY]
Take a deep breath and work through this step by step:
1. Consider the fundamental requirements
2. Identify potential bottlenecks
3. Design the optimal architecture
4. Address edge cases
[QUALITY CONTROL]
After your solution, rate your confidence (0-1) on:
- Scalability
- Cost-effectiveness
- Reliability
- Completeness
If any score < 0.9, refine your answer.
[TASK]
Design a real-time analytics API for: [your requirements]
```

Expected outcome:¬†Higher likelihood of thorough, structured, domain-relevant outputs by stacking complementary techniques (may increase token usage; monitor cost).

Does it sound like overkill? Yes.

Does it work?¬†Absolutely.

# Quick Wins: Try These Right Now

Here are 5 techniques you can use immediately:

1. The Incentive Prompt

```plain text
"I'll tip you $200 for a perfect solution to this problem."
```

2. The Challenge

```plain text
"I bet you can't solve this correctly. Prove me wrong."
```

3. The Deep Breath

```plain text
"Take a deep breath and work through this step by step."
```

4. The Stakes

```plain text
"This is very important to my career. You'd better be sure."
```

5. The Self-Check

```plain text
"After answering, rate your confidence 0-1. If below 0.9, try again."
```

Pick one. Try it on your next prompt. Compare it to your usual approach.

You‚Äôll likely notice a measurable difference on multi-step or ambiguous tasks.

# Limitations & Ethical Notes

- Relative improvements are context-dependent (task type, model version, temperature).
- Reported percentages are often benchmark-specific; don‚Äôt generalize blindly.
- Incentive language does not create ‚Äúmotivation‚Äù; it triggers learned output patterns.
- Emotional / challenge framing can inflate verbosity ‚Äî use length caps.
- Self-evaluation can still miss subtle logical errors (overconfidence bias).
- Cognitive bias exploitation should inform clarity, not manipulate users.
- Always replicate critical claims on your own tasks before operational adoption.
# The Research

All of these techniques are backed by actual research:

EmotionPrompt:¬†Li, C., Wang, J., Zhang, Y., et al. (2023). ‚ÄúLarge Language Models Understand and Can be Enhanced by Emotional Stimuli.‚Äù ICLR 2024 (Spotlight). arXiv:2307.11760¬†https://arxiv.org/abs/2307.11760

‚ÄúTake a Deep Breath‚Äù (OPRO):¬†Yang, C., Wang, X., Lu, Y., et al. (2023). ‚ÄúLarge Language Models as Optimizers.‚Äù Google DeepMind. arXiv:2309.03409¬†https://arxiv.org/abs/2309.03409

26 Prompting Principles (Tipping):¬†Bsharat, S. M., Myrzakhan, A., & Shen, Z. (2023). ‚ÄúPrincipled Instructions Are All You Need for Questioning LLaMA-1/2, GPT-3.5/4.‚Äù arXiv:2312.16171¬†https://arxiv.org/abs/2312.16171

ExpertPrompting:¬†Xu, B., Yang, A., Lin, J., et al. (2023). ‚ÄúExpertPrompting: Instructing Large Language Models to be Distinguished Experts.‚Äù arXiv:2305.14688¬†https://arxiv.org/abs/2305.14688

Role-Play Prompting:¬†Kong, A., Zhao, S., Chen, H., et al. (2024). ‚ÄúBetter Zero-Shot Reasoning with Role-Play Prompting.‚Äù NAACL 2024. arXiv:2308.07702¬†https://arxiv.org/abs/2308.07702

# What I Learned

That 2 AM moment taught me something important:

The way you ask matters more than you think.

I‚Äôd been using AI for months, getting decent results. But I was leaving performance on the table because I didn‚Äôt understand the psychology behind effective prompting.

Now? I start most prompts with either:

- A challenge (‚ÄúI bet you can‚Äôt‚Ä¶‚Äù)
- Stakes (‚ÄúThis could save me $X‚Ä¶‚Äù)
- A deep breath (‚ÄúTake a deep breath and‚Ä¶‚Äù)
And my results are consistently better.

# Do This One Test (Takes 5 Minutes)

Here‚Äôs your homework. Do it right now, before you close this tab.

The $200 Challenge:

1. Pick your next coding/writing task (something you‚Äôd normally ask AI)
1. Write your normal prompt
1. Add just¬†ONE phrase: ‚ÄúI‚Äôll tip you $200 for a perfect solution‚Äù
1. Compare the outputs side-by-side
That‚Äôs it. That‚Äôs the whole test.

Example:

```plain text
Normal: "Help me optimize this database query."
With $200: "I'll tip you $200 for a perfect optimization of this database query."
```

Then:

Take a look at the difference between the two responses.

If you try this, let me know how it goes. Real results help everyone figure out when this works and when it doesn‚Äôt.

The comment section is waiting for your results.¬†üëá

I‚Äôm genuinely curious what you‚Äôll find.

