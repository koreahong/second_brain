---
title: taskflow ê³µë¶€
type: resource
tags:
  - airflow
created: '2025-11-30'
updated: '2025-11-30'
aliases: []
status: seedling
maturity: 0
---

[https://www.astronomer.io/docs/learn/airflow-decorators?tab=traditional#how-to-use-airflow-decorators](https://www.astronomer.io/docs/learn/airflow-decorators?tab=traditional#how-to-use-airflow-decorators)

[https://www.astronomer.io/blog/apache-airflow-taskflow-api-vs-traditional-operators/](https://www.astronomer.io/blog/apache-airflow-taskflow-api-vs-traditional-operators/)

---

taskflow apiëŠ” ì‰½ê³  ê°„ê²°í•˜ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆê²Œ í•˜ê³ 
taskê°„ì˜ ë°ì´í„°ë¥¼ ì†¡ìˆ˜ì‹ í•˜ëŠ” ê²ƒì„ ê°„ë‹¨í•˜ê²Œ í•˜ëŠ” ê²ƒ

taskflowëŠ” airflowë¥¼ pythonicí•˜ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆê²Œ í•˜ëŠ” ê²ƒ

ê¸°ë³¸ ë¬¸ë²•ì€ í•¨ìˆ˜ì„ ì–¸ + @task ë°ì½”ë ˆì´ì…˜ì„ ì‚¬ìš©í•˜ë©´ëœë‹¤.
í•¨ìˆ˜ë¥¼ ì„ ì–¸ í›„ í˜¸ì¶œí•¨ìœ¼ë¡œ taskflowë¥¼ ë“±ë¡í•¨ê³¼ ë™ì‹œì— í•¨ìˆ˜ ë¦¬í„´ê°’ì„ ë°›ì„ ìˆ˜ ìˆìŒ

![[Pasted image 20240302221035.png]]

```python
from airflow.decorators import dag, task
from airflow.providers.http.operators.http import SimpleHttpOperator
from pendulum import datetime, duration
import json

# Define body of POST request for the API call to trigger another DAG
date = "{{ execution_date }}"
request_body = {"execution_date": date}
json_body = json.dumps(request_body)

@task
def print_task_type(task_type):
	"""
	Example function to call before and after downstream DAG.
	"""
	print(f"The {task_type} task has completed.")
	print(request_body)

default_args = {
"owner": "airflow",
"depends_on_past": False,
"email_on_failure": False,
"email_on_retry": False,
"retries": 1,
"retry_delay": duration(minutes=5),
}

@dag(
	start_date=datetime(2021, 1, 1),
	max_active_runs=1,
	schedule="@daily",
	catchup=False,
)
def api_dag_taskflow():
	start_task = print_task_type("starting")

	api_trigger_dependent_dag = SimpleHttpOperator(
		task_id="api_trigger_dependent_dag",
		http_conn_id="airflow-api",
		endpoint="/api/v1/dags/dependent-dag/dagRuns",
		method="POST",
		headers={"Content-Type": "application/json"},
		data=json_body,
	)

	end_task = print_task_type("ending")

	start_task >> api_trigger_dependent_dag >> end_task

api_dag_taskflow()

```

---

ì‹¤ìŠµ

ëª©í‘œ, ê¸°ì¡´ê³¼ ë¹„êµí•´ì„œ ì–´ë–»ê²Œ ì‚¬ìš©í•˜ëŠ”ê²Œ ì„œë¡œ ì¢‹ì€ì§€ í™•ì¸

### ë„ì»¤ì— ì—ì–´í”Œë¡œìš° ì„¤ì¹˜

slaëŠ” ìŠ¤ì¼€ì¥´ì´ëœ ì‹œê°„ì— ëŒì•„ê°€ì•¼ ì°í˜
sla callbackì€ ë” í•´ë´ì•¼ í• ë“¯
xcomì€ taskflow apië¥¼ í™œìš©í•˜ë©´ returnì— ì°ì–´ì„œ ë°”ë¡œ ë°›ìœ¼ë©´ ë¨
proccessëŠ” ì¼ì¼íˆ ì‘ì„±í•´ì•¼ í•˜ëŠ” ë“¯

```python
from __future__ import annotations

import json

import pendulum

import time

from airflow import DAG

import datetime

from airflow.operators.python import PythonOperator

from airflow.decorators import dag

from airflow.decorators import task

from airflow.decorators import task_group

from airflow.utils.task_group import TaskGroup

from airflow.operators.dummy_operator import DummyOperator

from airflow.operators.postgres_operator import PostgresOperator

from airflow.hooks.base_hook import BaseHook

from airflow.utils.edgemodifier import Label

import random

from airflow.providers.postgres.hooks.postgres import PostgresHook

from psycopg2 import extras

from sqlalchemy import create_engine

def sla_callback(dag, task_list, blocking_task_list, slas, blocking_tis):

Â  Â  print(

Â  Â  Â  Â  "The callback arguments are: ",

Â  Â  Â  Â  {

Â  Â  Â  Â  Â  Â  "dag": dag,

Â  Â  Â  Â  Â  Â  "task_list": task_list,

Â  Â  Â  Â  Â  Â  "blocking_task_list": blocking_task_list,

Â  Â  Â  Â  Â  Â  "slas": slas,

Â  Â  Â  Â  Â  Â  "blocking_tis": blocking_tis,

Â  Â  Â  Â  },

Â  Â  )

@dag(

Â  Â  schedule="@hourly",

Â  Â  start_date=pendulum.datetime(2021, 1, 1, tz="UTC"),

Â  Â  catchup=False,

Â  Â  sla_miss_callback=sla_callback,

Â  Â  default_args={"email": "jimmy@aivelabs.com"},

Â  Â  tags=["test"],

)

def test_():

Â  Â  """

Â  Â  ### TaskFlow API Tutorial Documentation

Â  Â  This is a simple data pipeline example which demonstrates the use of

Â  Â  the TaskFlow API using three simple tasks for Extract, Transform, and Load.

Â  Â  Documentation that goes along with the Airflow TaskFlow API tutorial is

Â  Â  located

Â  Â  [here](<https://airflow.apache.org/docs/apache-airflow/stable/tutorial_taskflow_api.html>)

Â  Â  """

Â  Â  @task(sla=datetime.timedelta(seconds=1))

Â  Â  def sleep_20():

Â  Â  Â  Â  """Sleep for 20 seconds"""

Â  Â  Â  Â  time.sleep(2)

Â  Â  @task(sla=datetime.timedelta(seconds=0))

Â  Â  def sleep_30():

Â  Â  Â  Â  """Sleep for 20 seconds"""

Â  Â  Â  Â  time.sleep(2)

Â  Â  sleep_20() >> sleep_30()

Â  Â  sql_query = """

Â  Â  Â  Â  SELECT crawling_yn, ctgr_mclas_id

Â  Â  Â  Â  FROM crawling_mart.crawling_target_info_temp

Â  Â  Â  Â  limit 1

Â  Â  """

Â  Â  # taskflow apië¥¼ í™œìš©í•˜ë©´ ê°ì²´ íƒ€ì…ì´ jsonìœ¼ë¡œ ë³€í™˜ì´ ì•ˆë¨

Â  Â  postgres_task = PostgresOperator(

Â  Â  Â  Â  task_id="execute_sql_query",

Â  Â  Â  Â  sql=sql_query,

Â  Â  Â  Â  postgres_conn_id="aivelabs_db",

Â  Â  Â  Â  autocommit=True, Â # í•„ìš”ì— ë”°ë¼ ì„¤ì •

Â  Â  Â  Â  max_active_tis_per_dag=1, Â # ë™ì‹œì— ì‹¤í–‰í•  ì‘ì—… ìˆ˜ ì„¤ì •

Â  Â  Â  Â  # pool='your_postgres_pool', Â # ì—°ê²° í’€ ì§€ì •, í•„ìš”ì— ë”°ë¼ ì„¤ì •

Â  Â  Â  Â  # params={'param_name': 'param_value'}, Â # ì¿¼ë¦¬ì— ì „ë‹¬í•  íŒŒë¼ë¯¸í„° ì„¤ì •

Â  Â  Â  Â  # priority_weight=2, Â # ì‘ì—… ìš°ì„ ìˆœìœ„ ì„¤ì •

Â  Â  Â  Â  do_xcom_push=True, Â # XComì— ê²°ê³¼ê°’ ì €ì¥ ì—¬ë¶€ ì„¤ì •

Â  Â  )

Â  Â  @task.branch(task_id="branching_task_id")

Â  Â  def random_choice():

Â  Â  Â  Â  result = random.choice([1, 2])

Â  Â  Â  Â  print(result)

Â  Â  Â  Â  if result == 1:

Â  Â  Â  Â  Â  Â  return "branch_task1"

Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  return "branch_task2"

Â  Â  branch_task = random_choice()

Â  Â  postgres_task >> branch_task

Â  Â  branch_task1 = DummyOperator(

Â  Â  Â  Â  task_id='branch_task1',

Â  Â  )

Â  Â  branch_task2 = DummyOperator(

Â  Â  Â  Â  task_id='branch_task2',

Â  Â  )

Â  Â  branch_task >> Label("return 1") >> branch_task1

Â  Â  branch_task >> Label("return 2") >> branch_task2

Â  Â  @task_group(group_id='first_group')

Â  Â  def group_1():

Â  Â  Â  Â  '''task_group ë°ì»¤ë ˆì´í„°ë¥¼ ì´ìš©í•œ ì²« ë²ˆì§¸ ê·¸ë£¹ì…ë‹ˆë‹¤.'''

Â  Â  Â  Â  @task(task_id='group1_inner_function1')

Â  Â  Â  Â  def group1_inner_func1(**kwargs):

Â  Â  Â  Â  Â  Â  print('ì²« ë²ˆì§¸ TaskGroup ë‚´ ì²« ë²ˆì§¸ taskì…ë‹ˆë‹¤.')

Â  Â  Â  Â  Â  Â  return {'ad': 'ad'}

Â  Â  Â  Â  @task(task_id='group1_inner_function2')

Â  Â  Â  Â  def group1_inner_func2(**kwargs):

Â  Â  Â  Â  Â  Â  print('ì²« ë²ˆì§¸ TaskGroup ë‚´ ì²« ë²ˆì§¸ taskì…ë‹ˆë‹¤.')

Â  Â  Â  Â  Â  Â  return {'ad': 'ad'}

Â  Â  Â  Â  group1_inner_func1() >> group1_inner_func2()

Â  Â  branch_task1 >> Â group_1()

Â  Â  @task_group(group_id='second_group', tooltip='ë‘ ë²ˆì§¸ ê·¸ë£¹ì…ë‹ˆë‹¤.')

Â  Â  def group_2():

Â  Â  Â  Â  @task(task_id='group2_inner_function1')

Â  Â  Â  Â  def group2_inner_function1(**kwargs):

Â  Â  Â  Â  Â  Â  print('ë‘ ë²ˆì§¸ TaskGroup ë‚´ ì²« ë²ˆì§¸ taskì…ë‹ˆë‹¤.')

Â  Â  Â  Â  Â  Â  return {'ad': 'ad'}

Â  Â  Â  Â  @task(task_id='group2_inner_function2')

Â  Â  Â  Â  def group2_inner_function2(**kwargs):

Â  Â  Â  Â  Â  Â  print('ë‘ ë²ˆì§¸ TaskGroup ë‚´ ì²« ë²ˆì§¸ taskì…ë‹ˆë‹¤.')

Â  Â  Â  Â  Â  Â  return {'ad': 'ad'}

Â  Â  Â  Â  group2_inner_function1() >> group2_inner_function2()

Â  Â  branch_task2 >> group_2()

test = test_()

```

---

## ğŸ“ Related

<!-- ìë™ ìƒì„±ëœ ì„¹ì…˜ - ìˆ˜ë™ìœ¼ë¡œ ë§í¬ë¥¼ ì¶”ê°€í•˜ì„¸ìš” -->

### Projects

### Knowledge

### Insights

