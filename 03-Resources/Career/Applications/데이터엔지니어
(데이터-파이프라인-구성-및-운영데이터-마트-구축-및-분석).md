---
title: 데이터엔지니어 (데이터 파이프라인 구성 및 운영/데이터 마트 구축 및 분석)
type: resource
tags:
- 커리어-지원내역
---

<details>
<summary>JD</summary>

# 데이터엔지니어

# (데이터 파이프라인 구성 및 운영/데이터 마트 구축 및 분석)

[조직 소개]

기업정보개발실은 기업정보 서비스를 제공하기 위한 통합 IT 조직으로 웹, 앱, API, 대외계, DW, 인프라 운영에 필요한 IT역량을 통합적으로 보유하고 있습니다. 팀 간 스쿼드 형태로 유기적 협업을 기본으로 DevOps 자동화를 지향하고 기술공유, 지속적인 개선 및 혁신을 추구합니다.

구성원들은 백엔드, 프론트엔드 개발과 ETL, NiFi 등을 이용한 데이터 파이프라인 구성 역량을 갖고 있으며 데이터 분석, 가공, 모델링 외에도 DevOps, 아키텍처, AI 등 신기술 수용에 적극적입니다. 또한 JIRA, Confluence, Git 등 협업 툴을 적극 운용하고 있습니다.

[담당 업무]

1. 다양한 소스에서 발생하는 데이터를 수집, 정제, 적재하여 DW (HANA IQ 등)까지 데이터 파이프라인을 설계, 구축, 운영하고 ETL 도구(Informatica, Spring Batch, NiFi, Flink)를 활용해 데이터 마트를 구축하고 분석

2. 방대하고 다양한 기업 데이터를 최적의 플로우를 고려한 파이프라인 설계부터 DW 데이터 마트 구축까지 폭넓은 업무 수행

[지원 자격]

ㆍ 대졸 이상(4년제) 또는 졸업예정자

ㆍ 기초 프로그래밍 능력 (Java, Python, SQL)

ㆍ 데이터 이해 및 처리에 대한 관심과 역량

[우대 요건]

ㆍ 컴퓨터과학, 컴퓨터공학 등 관련 전공 우대

ㆍ 데이터 파이프라인 구성 및 ETL 실무 경험자

ㆍ 데이터베이스 및 SQL 역량 보유자

ㆍ 데이터 모델링 및 DW설계 지식 보유자

ㆍ HANA IQ 또는 유사 DW 플랫폼 설계 경험 보유자

ㆍ 문제해결 및 커뮤니케이션 능력 보유자

ㆍ SAP ASE, HANA, IQ 심화 경험, 데이터 연동, 이관, 마이그레이션 경험 보유자

ㆍ 빅데이터 분석 툴 연동 경험 보유자 (Spark, Kafka 등과 연계하여 실시간 혹은 배치 파이프라인 구성)

ㆍ 메타데이터 관리, 데이터 품질 모니터링 프로세스 구축 경험 보유자

ㆍ 기존 프로세스 개선 및 효율성 향상을 위한 제안과 실행 경험 보유자

[필독 사항]

기업정보개발실은 하나의 고정된 업무만 전담하기보다는, 서로 다른 분야가 유기적으로 얽혀 있는 조직입니다. 한 사람이 하나의 기술만을 집중하는 대신, 다양한 업무와 경험을 폭넓게 쌓을 수 있는 환경입니다. 특정 한 분야에 국한되지 않고, 팀원 간 협업을 통해 복합적인 프로젝트를 함께 이끌어 나가게 됩니다.

</details>

<details>
<summary>기업분석</summary>

CB사, 

개인신용정보 / 기업신용평가

본인인증 / 나이스 지키미

</details>

<details>
<summary>면접 질문</summary>

데이터 품질관리 수준을 어떻게 유지를 하였는지?

⇒ 기준에 대해서 cafe24 대시보드 매출액 기준으로 잡았고 데이터 타입별로 확인해야하는 검증 종류를 관리해서 진행함.

쿠팡이츠 정규직 전환 가능한 거였냐 / 왜 나왔냐

⇒ 다양하게 시도해보고 싶은 것이 있었는데, 권한 이슈가 있어서, 시간이 오래걸릴거 같아서 나왔다

=⇒ 애초에 말했던 업무 내용과 전혀 다른 업무를 해서, 퇴사함.

DB2DB 새로운 데이터 파이프라인을 만들어야 하는데 어떻게 만들래

⇒ sqoop으로 db2db해서 hdfs 만들고 하둡으로 옮기고 iceberg 처리 대시보드는 tableau

이걸 하기 위해서 어떤 역량이 가장 필요하냐고 생각하냐?

⇒ 문제해결 능력이다. 데이터 파이프라인을 처리하다보면 원인을 알 수 없는 오류들이 많이 발생한다.
     그걸 구조적으로 기술적으로 재발하지 않게 풀어나갈 때 필요한 부분인거 같다. 

새롭게 배워본다고 한다면 어떤 부분을 보완하고 싶냐

⇒ 지금까지 여러 브랜드의 데이터를 관리하는데 품질 관리나 데이터 마트 생성하는 부분을 효율적으로 관리하는 부분을 진행했고
     앞으로는 데이터 수집하는 단계를 좀더

DB 성능 최적화 어디까지 해봤냐

⇒ 인덱스, 파티셔닝

취미생활이 뭐냐

⇒ 런닝

직장에 갈등이 있었다면 어떻게 해결했냐

⇒ 팀을 생각해서

에이브랩스라는 회사는 어떻게 알고 들어갔냐

⇒ 지인들이 내가 어떤거 하고싶은지 알고 있으니까 추천해줬다

크롤링할때 예외처리 같은 것을 어떻게 진행했었는지

⇒ 이전에 element key값과 현재 key값을 비교해서 configuration 관리 진행.

SLA 기준을 높게 유지한거 같은데 어떻게 가능했는지

⇒ 메모리 사용률이 높으면 worker 수를 늘림, 빅쿼리 최적화

업무외적 소양?

⇒ 질문을 제대로 못들음.

</details>