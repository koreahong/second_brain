#!/usr/bin/env python3
"""
Vault í¬ë§· ì •ê·œí™” ìŠ¤í¬ë¦½íŠ¸

Notionì—ì„œ ë§ˆì´ê·¸ë ˆì´ì…˜ëœ ë…¸íŠ¸ë“¤ì˜ frontmatter, íƒœê·¸, ë³¸ë¬¸ í¬ë§·ì„
Second Brain êµ¬ì¡°ì— ë§ê²Œ ì¼ê´€ì„± ìˆê²Œ ì •ë¦¬í•©ë‹ˆë‹¤.
"""

import os
import re
from pathlib import Path
from typing import Dict, List, Any, Optional
import yaml
from datetime import datetime


class VaultNormalizer:
    """Vault ë…¸íŠ¸ ì •ê·œí™”"""

    def __init__(self, vault_path: str):
        self.vault_path = Path(vault_path)
        self.stats = {
            'processed': 0,
            'modified': 0,
            'errors': 0,
            'skipped': 0
        }

        # ì¹´í…Œê³ ë¦¬ë³„ frontmatter ìŠ¤í‚¤ë§ˆ
        self.schemas = {
            'life-insights': {
                'required': ['title', 'date', 'type'],
                'optional': ['week', 'tags', 'related'],
                'remove': ['source', 'notion_id', 'imported', 'database',
                          'ì ìš©í•  ê²ƒ', 'íšŒê³ ì¢…ë¥˜', 'ë‚ ì§œ(ìƒì„±ë‚ ì§œ)', 'ì£¼ì œ(APIìš©)',
                          'ì‚¬ì§„', 'ê¹¨ë‹¬ì€ ê²ƒ', 'ë³¸ ê²ƒ', 'ì£¼ì°¨', 'ì¼ê¸°', 'ë‚ ì§œ']
            },
            'weekly': {
                'required': ['title', 'date', 'type'],
                'optional': ['week', 'tags', 'summary', 'achievements', 'challenges',
                            'learnings', 'next_week', 'related_projects'],
                'remove': ['source', 'notion_id', 'imported', 'database',
                          'ğŸ”§ ëŒ€ì²˜ ë°©ë²•', 'ğŸŒŸ í•œ ì¤„ ìš”ì•½', 'âœ¨ ì„±ê³¼ / ê°œì„ ì ',
                          'ğŸš© ë¬¸ì œ ìƒí™©', 'ì—­ëŸ‰', 'ğŸ™Œ ë°°ìš´ ì ']
            },
            'projects': {
                'required': ['title', 'status', 'created'],
                'optional': ['tags', 'jira_key', 'related', 'updated', 'completed'],
                'remove': ['source', 'notion_id', 'imported', 'database', 'íƒœê·¸',
                          'Git ì»¤ë°‹', 'Jira Key', 'ìƒíƒœ', 'ì‹œí–‰ì°©ì˜¤ (Trial & Error)',
                          'ì—…ë¬´ êµ¬ìƒ 1', 'ì‘ì—… íˆìŠ¤í† ë¦¬', 'ìƒìœ„ í•­ëª©', 'Jira ê²°ê³¼',
                          'ì—…ë¬´ êµ¬ìƒ', 'ìƒì„± ì¼ì‹œ', 'í•˜ìœ„ í•­ëª©']
            },
            'resources': {
                'required': ['title', 'category'],
                'optional': ['tags', 'url', 'author', 'date', 'summary', 'related'],
                'remove': ['source', 'notion_id', 'imported', 'database', 'í•˜ìœ„ í•­ëª©',
                          'êµ¬ìƒê¸°ë¡', 'êµ¬ë¶„', 'ë§í¬', 'ìµœì¢…í¸ì§‘ì‹œê°', 'ì œëª©',
                          'ìƒìœ„ í•­ëª©', 'ë‚ ì§œ', 'PARA']
            }
        }

        # íƒœê·¸ ì •ê·œí™” ë§¤í•‘
        self.tag_mapping = {
            # ì œê±°í•  ì„ì‹œ íƒœê·¸
            'notion-import': None,
            'ë³¸ê¹¨ì ': None,
            'íšŒê³ ë¡': None,
            'ì—…ë¬´ë¦¬ìŠ¤íŠ¸': None,
            'ë ˆí¼ëŸ°ìŠ¤': None,

            # ê¸°ìˆ  íƒœê·¸ (ì†Œë¬¸ì, í•˜ì´í”ˆ)
            'Airflow': 'airflow',
            'DBT': 'dbt',
            'DataHub': 'datahub',
            'PostgreSQL': 'postgresql',
            'Snowflake': 'snowflake',
            'AWS': 'aws',
            'Docker': 'docker',
            'Kubernetes': 'kubernetes',
            'Python': 'python',

            # ì—­ëŸ‰ íƒœê·¸ (í•œê¸€ ìœ ì§€, ì¼ê´€ì„±)
            'ì˜ì‚¬ì†Œí†µ': 'ì˜ì‚¬ì†Œí†µ',
            'ë¬¸ì„œí™”': 'ë¬¸ì„œí™”',
            'ë¬¸ì œí•´ê²°': 'ë¬¸ì œí•´ê²°',
            'êµ¬ì¡°í™”': 'êµ¬ì¡°í™”',
            'ë°ì´í„°ëª¨ë¸ë§': 'ë°ì´í„°ëª¨ë¸ë§',
            'ê±°ë²„ë„ŒìŠ¤': 'ê±°ë²„ë„ŒìŠ¤',
        }

    def detect_category(self, file_path: Path) -> str:
        """íŒŒì¼ ê²½ë¡œë¡œ ì¹´í…Œê³ ë¦¬ ê°ì§€"""
        path_str = str(file_path)

        if '30-Flow/Life-Insights' in path_str:
            return 'life-insights'
        elif 'Experience/Weekly' in path_str:
            return 'weekly'
        elif 'Projects/' in path_str:
            return 'projects'
        elif '03-Resources/' in path_str:
            return 'resources'

        return 'unknown'

    def parse_frontmatter(self, content: str) -> tuple[Optional[Dict], str]:
        """Frontmatter íŒŒì‹±"""
        if not content.startswith('---'):
            return None, content

        try:
            parts = content.split('---', 2)
            if len(parts) < 3:
                return None, content

            frontmatter = yaml.safe_load(parts[1])
            body = parts[2].strip()

            return frontmatter, body
        except Exception as e:
            print(f"âš ï¸  Frontmatter íŒŒì‹± ì˜¤ë¥˜: {e}")
            return None, content

    def normalize_frontmatter(self, frontmatter: Dict, category: str) -> Dict:
        """Frontmatter ì •ê·œí™”"""
        if not frontmatter:
            return {}

        schema = self.schemas.get(category, self.schemas['resources'])
        normalized = {}

        # 1. ì œê±°í•  í•„ë“œ ì œê±°
        for key in schema['remove']:
            frontmatter.pop(key, None)

        # 2. ë‚ ì§œ í•„ë“œ í†µì¼
        date_value = None
        for date_key in ['date', 'ë‚ ì§œ', 'ë‚ ì§œ(ìƒì„±ë‚ ì§œ)', 'ìƒì„± ì¼ì‹œ', 'ìµœì¢…í¸ì§‘ì‹œê°']:
            if date_key in frontmatter:
                date_value = frontmatter.pop(date_key)
                break

        if date_value:
            # ISO í˜•ì‹ â†’ YYYY-MM-DD
            if isinstance(date_value, str):
                try:
                    dt = datetime.fromisoformat(date_value.replace('Z', '+00:00'))
                    normalized['date'] = dt.strftime('%Y-%m-%d')
                except:
                    normalized['date'] = date_value
            else:
                normalized['date'] = str(date_value)

        # 3. ì œëª©
        if 'title' in frontmatter:
            normalized['title'] = frontmatter['title']

        # 4. íƒ€ì… (ì¹´í…Œê³ ë¦¬ë³„)
        if category == 'life-insights':
            normalized['type'] = frontmatter.get('type', frontmatter.get('íšŒê³ ì¢…ë¥˜', 'insight'))
        elif category == 'weekly':
            normalized['type'] = 'weekly-reflection'
        elif category == 'projects':
            normalized['type'] = 'project'
            # ìƒíƒœ ë§¤í•‘
            status_map = {
                'ë¦¬ìŠ¤íŠ¸ì—…': 'planned',
                'ì§„í–‰ì¤‘': 'active',
                'ì™„ë£Œ': 'completed',
                'ë³´ë¥˜': 'on-hold'
            }
            old_status = frontmatter.get('ìƒíƒœ', frontmatter.get('status', 'planned'))
            normalized['status'] = status_map.get(old_status, old_status)
        elif category == 'resources':
            normalized['type'] = 'resource'
            # êµ¬ë¶„ â†’ category
            categories = frontmatter.get('êµ¬ë¶„', [])
            if categories:
                normalized['category'] = categories[0] if isinstance(categories, list) else categories

        # 5. íƒœê·¸ ì •ê·œí™”
        tags = frontmatter.get('tags', [])
        if not isinstance(tags, list):
            tags = [tags] if tags else []

        # ì—­ëŸ‰ íƒœê·¸ ì¶”ê°€
        competencies = frontmatter.get('ì—­ëŸ‰', [])
        if competencies and isinstance(competencies, list):
            tags.extend(competencies)

        normalized_tags = []
        for tag in tags:
            if tag in self.tag_mapping:
                new_tag = self.tag_mapping[tag]
                if new_tag:  # Noneì´ ì•„ë‹Œ ê²½ìš°ë§Œ
                    normalized_tags.append(new_tag)
            else:
                normalized_tags.append(tag)

        # ì¤‘ë³µ ì œê±°
        normalized['tags'] = sorted(list(set(normalized_tags)))

        # 6. ê¸°íƒ€ ìœ ìš©í•œ í•„ë“œ ìœ ì§€
        for key in ['week', 'summary', 'url', 'author', 'jira_key', 'related']:
            if key in frontmatter and frontmatter[key]:
                normalized[key] = frontmatter[key]

        # 7. created/updated
        if category == 'projects':
            if 'ìƒì„± ì¼ì‹œ' in frontmatter:
                try:
                    dt = datetime.fromisoformat(frontmatter['ìƒì„± ì¼ì‹œ'].replace('Z', '+00:00'))
                    normalized['created'] = dt.strftime('%Y-%m-%d')
                except:
                    pass

        return normalized

    def normalize_body(self, body: str, category: str, frontmatter: Dict) -> str:
        """ë³¸ë¬¸ í¬ë§· ì •ê·œí™”"""
        if not body or body.strip() == '':
            # ë¹ˆ ë³¸ë¬¸ì¸ ê²½ìš° ê¸°ë³¸ êµ¬ì¡° ìƒì„±
            if category == 'life-insights':
                title = frontmatter.get('title', 'ì œëª© ì—†ìŒ')
                date = frontmatter.get('date', '')
                week = frontmatter.get('week', '')

                body = f"""# {title}

> **ë‚ ì§œ**: {date}
> **ì£¼ì°¨**: {week}ì£¼ì°¨

## ë³¸ ê²ƒ

(ë‚´ìš© ì¶”ê°€ í•„ìš”)

## ê¹¨ë‹¬ì€ ê²ƒ

(ë‚´ìš© ì¶”ê°€ í•„ìš”)

## ì ìš©í•  ê²ƒ

(ë‚´ìš© ì¶”ê°€ í•„ìš”)
"""
            elif category == 'weekly':
                body = """## ğŸŒŸ í•œ ì¤„ ìš”ì•½

(ìš”ì•½ ì¶”ê°€)

## âœ¨ ì„±ê³¼ / ê°œì„ ì 

-

## ğŸš© ë¬¸ì œ ìƒí™©

-

## ğŸ™Œ ë°°ìš´ ì 

-

## ğŸ”§ ëŒ€ì²˜ ë°©ë²•

-

## ğŸ“‹ ë‹¤ìŒ ì£¼ ê³„íš

-

---

### Related Projects

-
"""
            return body

        # ë§í¬ í¬ë§· ì •ê·œí™” (ğŸ”– ì œê±°)
        body = re.sub(r'ğŸ”–\s*\[', '[', body)

        # ë¶ˆí•„ìš”í•œ ë¹ˆ ì¤„ ì œê±° (3ê°œ ì´ìƒ ì—°ì† â†’ 2ê°œ)
        body = re.sub(r'\n{3,}', '\n\n', body)

        return body.strip()

    def process_file(self, file_path: Path) -> bool:
        """ê°œë³„ íŒŒì¼ ì²˜ë¦¬"""
        try:
            # ì¹´í…Œê³ ë¦¬ ê°ì§€
            category = self.detect_category(file_path)
            if category == 'unknown':
                self.stats['skipped'] += 1
                return False

            # íŒŒì¼ ì½ê¸°
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()

            # Frontmatter íŒŒì‹±
            frontmatter, body = self.parse_frontmatter(content)

            if not frontmatter:
                self.stats['skipped'] += 1
                return False

            # ì •ê·œí™”
            normalized_fm = self.normalize_frontmatter(frontmatter, category)
            normalized_body = self.normalize_body(body, category, normalized_fm)

            # ìƒˆ ì½˜í…ì¸  ìƒì„±
            new_content = "---\n"
            new_content += yaml.dump(normalized_fm, allow_unicode=True, sort_keys=False)
            new_content += "---\n\n"
            new_content += normalized_body

            # ë³€ê²½ì‚¬í•­ í™•ì¸
            if content != new_content:
                # íŒŒì¼ ì“°ê¸°
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(new_content)

                self.stats['modified'] += 1
                print(f"âœ… {file_path.relative_to(self.vault_path)}")
                return True
            else:
                self.stats['skipped'] += 1
                return False

        except Exception as e:
            print(f"âŒ {file_path.relative_to(self.vault_path)}: {e}")
            self.stats['errors'] += 1
            return False
        finally:
            self.stats['processed'] += 1

    def process_directory(self, directory: Path):
        """ë””ë ‰í† ë¦¬ ì¬ê·€ ì²˜ë¦¬"""
        for file_path in directory.rglob('*.md'):
            # íŠ¹ì • íŒŒì¼/í´ë” ì œì™¸
            if any(skip in str(file_path) for skip in [
                'README.md',
                'automation/',
                '99-Assets/',
                '.git/',
                '.obsidian/'
            ]):
                continue

            self.process_file(file_path)

    def run(self, dry_run: bool = False):
        """ì „ì²´ ì²˜ë¦¬ ì‹¤í–‰"""
        print(f"\n{'='*60}")
        print(f"ğŸš€ Vault í¬ë§· ì •ê·œí™” ì‹œì‘")
        print(f"{'='*60}\n")

        if dry_run:
            print("âš ï¸  DRY RUN ëª¨ë“œ - ì‹¤ì œ íŒŒì¼ì€ ìˆ˜ì •í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n")

        # ì£¼ìš” ë””ë ‰í† ë¦¬ ì²˜ë¦¬
        directories = [
            self.vault_path / '30-Flow' / 'Life-Insights',
            self.vault_path / '02-Areas' / 'í¬ë˜í”„íŠ¸í…Œí¬ë†€ë¡œì§€ìŠ¤',
            self.vault_path / '03-Resources',
        ]

        for directory in directories:
            if directory.exists():
                print(f"\nğŸ“ {directory.relative_to(self.vault_path)} ì²˜ë¦¬ ì¤‘...\n")
                self.process_directory(directory)

        # ê²°ê³¼ ì¶œë ¥
        print(f"\n{'='*60}")
        print(f"âœ¨ ì²˜ë¦¬ ì™„ë£Œ")
        print(f"{'='*60}")
        print(f"  ğŸ“Š ì „ì²´ íŒŒì¼: {self.stats['processed']}")
        print(f"  âœ… ìˆ˜ì •ë¨: {self.stats['modified']}")
        print(f"  â­ï¸  ê±´ë„ˆëœ€: {self.stats['skipped']}")
        print(f"  âŒ ì˜¤ë¥˜: {self.stats['errors']}")
        print(f"{'='*60}\n")


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    import argparse

    parser = argparse.ArgumentParser(description='Vault í¬ë§· ì •ê·œí™”')
    parser.add_argument('--vault', default='/Users/qraft_hongjinyoung/DAE-Second-Brain',
                       help='Vault ê²½ë¡œ')
    parser.add_argument('--dry-run', action='store_true',
                       help='ì‹¤ì œ ìˆ˜ì •í•˜ì§€ ì•Šê³  ë¯¸ë¦¬ë³´ê¸°ë§Œ')

    args = parser.parse_args()

    normalizer = VaultNormalizer(args.vault)
    normalizer.run(dry_run=args.dry_run)


if __name__ == '__main__':
    main()
