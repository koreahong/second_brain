"""
Weekly Review Agent

ì£¼ê°„ ë¬¸ì„œ ë¶„ì„ ë° ë¦¬í¬íŠ¸ ìƒì„±
"""

from pathlib import Path
from typing import Dict, List
from datetime import datetime, timedelta
from collections import Counter
from ..core.document_scorer import DocumentQualityScorer
from ..core.note_classifier import NoteClassifier
from ..core.link_suggester import LinkSuggester
from ..utils.markdown_utils import MarkdownNote
from ..core.config import WEEKLY_REVIEW_CONFIG, FOLDERS


class WeeklyReviewer:
    """ì£¼ê°„ ë¦¬ë·° ì—ì´ì „íŠ¸"""

    def __init__(self, vault_root: Path):
        self.vault_root = vault_root
        self.scorer = DocumentQualityScorer(vault_root)
        self.classifier = NoteClassifier(vault_root)
        self.link_suggester = LinkSuggester(vault_root)

    def generate_weekly_report(self, week: str = None) -> Dict:
        """
        ì£¼ê°„ ë¦¬í¬íŠ¸ ìƒì„±

        Args:
            week: YYYY-WXX í˜•ì‹ (ì˜ˆ: 2025-W48)

        Returns:
            {
                'period': '2025-W48',
                'statistics': {...},
                'top_documents': [...],
                'needs_attention': {...},
                'network_insights': {...},
                'recommendations': [...]
            }
        """
        if week is None:
            week = self._get_current_week()

        print(f"\nğŸ“… Generating Weekly Report for {week}")
        print("="*50)

        # 1. í†µê³„
        print("\n1ï¸âƒ£  Calculating statistics...")
        statistics = self._calculate_statistics()

        # 2. ìš°ìˆ˜ ë¬¸ì„œ
        print("2ï¸âƒ£  Finding top documents...")
        top_documents = self._get_top_documents()

        # 3. ì£¼ì˜ í•„ìš” ë¬¸ì„œ
        print("3ï¸âƒ£  Identifying documents needing attention...")
        needs_attention = self._find_documents_needing_attention()

        # 4. ë„¤íŠ¸ì›Œí¬ ë¶„ì„
        print("4ï¸âƒ£  Analyzing knowledge network...")
        network_insights = self._analyze_network()

        # 5. ê°œì„  ì œì•ˆ
        print("5ï¸âƒ£  Generating recommendations...")
        recommendations = self._generate_recommendations(
            statistics,
            needs_attention,
            network_insights
        )

        report = {
            'period': week,
            'generated_at': datetime.now().isoformat(),
            'statistics': statistics,
            'top_documents': top_documents,
            'needs_attention': needs_attention,
            'network_insights': network_insights,
            'recommendations': recommendations
        }

        print("\nâœ“ Weekly report generated successfully\n")
        return report

    def _calculate_statistics(self) -> Dict:
        """ì „ì²´ í†µê³„ ê³„ì‚°"""
        all_notes = {}
        new_this_week = []
        grade_dist = Counter()
        type_dist = Counter()

        for md_file in self.vault_root.rglob('*.md'):
            if self._should_exclude(md_file):
                continue

            try:
                note = MarkdownNote(md_file)

                # ì ìˆ˜ ê³„ì‚°
                score_result = self.scorer.score_document(md_file)
                grade = score_result['grade']
                grade_dist[grade] += 1

                # íƒ€ì… ë¶„ë¥˜
                classification = self.classifier.classify(md_file)
                note_type = classification['note_type']
                type_dist[note_type] += 1

                # ì´ë²ˆ ì£¼ ìƒì„± ì—¬ë¶€
                if self._is_created_this_week(note, md_file):
                    new_this_week.append(str(md_file.relative_to(self.vault_root)))

                all_notes[str(md_file.relative_to(self.vault_root))] = {
                    'score': score_result['total_score'],
                    'grade': grade,
                    'type': note_type
                }

            except Exception as e:
                continue

        # í‰ê·  ì ìˆ˜
        total_score = sum(data['score'] for data in all_notes.values())
        avg_score = total_score / len(all_notes) if all_notes else 0

        return {
            'total_notes': len(all_notes),
            'new_this_week': len(new_this_week),
            'new_notes_list': new_this_week[:10],  # ìµœëŒ€ 10ê°œë§Œ
            'average_score': round(avg_score, 1),
            'grade_distribution': dict(grade_dist),
            'type_distribution': dict(type_dist)
        }

    def _get_top_documents(self, limit: int = 10) -> List[Dict]:
        """ìš°ìˆ˜ ë¬¸ì„œ ì°¾ê¸°"""
        scored_notes = []

        for md_file in self.vault_root.rglob('*.md'):
            if self._should_exclude(md_file):
                continue

            try:
                score_result = self.scorer.score_document(md_file)
                note = MarkdownNote(md_file)

                scored_notes.append({
                    'path': str(md_file.relative_to(self.vault_root)),
                    'title': note.frontmatter.get('title', md_file.stem),
                    'score': score_result['total_score'],
                    'grade': score_result['grade']
                })
            except Exception:
                continue

        # ì ìˆ˜ìˆœ ì •ë ¬
        top_notes = sorted(scored_notes, key=lambda x: x['score'], reverse=True)[:limit]
        return top_notes

    def _find_documents_needing_attention(self) -> Dict:
        """ì£¼ì˜ í•„ìš” ë¬¸ì„œ ì°¾ê¸°"""
        config = WEEKLY_REVIEW_CONFIG

        low_score = []
        orphaned = []
        stale = []
        unclassified_inbox = []

        # Link suggester ì¸ë±ìŠ¤ êµ¬ì¶•
        self.link_suggester.build_index()

        for md_file in self.vault_root.rglob('*.md'):
            if self._should_exclude(md_file):
                continue

            try:
                note = MarkdownNote(md_file)
                rel_path = str(md_file.relative_to(self.vault_root))

                # 1. ì €í’ˆì§ˆ ë¬¸ì„œ
                score_result = self.scorer.score_document(md_file)
                if score_result['total_score'] < config['low_score_threshold']:
                    low_score.append({
                        'path': rel_path,
                        'title': note.frontmatter.get('title', md_file.stem),
                        'score': score_result['total_score']
                    })

                # 2. ê³ ì•„ ë…¸íŠ¸
                backlinks = self.link_suggester.find_backlinks(md_file)
                outgoing = len(note.get_links())
                if outgoing == 0 and len(backlinks) == 0:
                    orphaned.append({
                        'path': rel_path,
                        'title': note.frontmatter.get('title', md_file.stem)
                    })

                # 3. ì˜¤ë˜ëœ ë¬¸ì„œ
                days_old = self._days_since_modified(md_file)
                if days_old > config['stale_days']:
                    stale.append({
                        'path': rel_path,
                        'title': note.frontmatter.get('title', md_file.stem),
                        'days_old': days_old
                    })

                # 4. Inboxì— ì˜¤ë˜ ë¨¸ë¬¼ëŸ¬ ìˆëŠ” ë…¸íŠ¸
                if rel_path.startswith(FOLDERS['inbox']):
                    days_in_inbox = self._days_since_created(md_file)
                    if days_in_inbox > 7:  # 7ì¼ ì´ìƒ
                        unclassified_inbox.append({
                            'path': rel_path,
                            'title': note.frontmatter.get('title', md_file.stem),
                            'days_in_inbox': days_in_inbox
                        })

            except Exception:
                continue

        return {
            'low_score': sorted(low_score, key=lambda x: x['score'])[:20],
            'orphaned': orphaned[:20],
            'stale': sorted(stale, key=lambda x: x['days_old'], reverse=True)[:20],
            'unclassified_inbox': sorted(unclassified_inbox, key=lambda x: x['days_in_inbox'], reverse=True)
        }

    def _analyze_network(self) -> Dict:
        """ì§€ì‹ ë„¤íŠ¸ì›Œí¬ ë¶„ì„"""
        # Link suggester ì‚¬ìš©
        if not self.link_suggester._note_cache:
            self.link_suggester.build_index()

        network_stats = self.link_suggester.generate_network_stats()

        # ì¶”ê°€ ë¶„ì„
        # 1. í—ˆë¸Œ ë…¸íŠ¸ (ê°€ì¥ ë§ì´ ì°¸ì¡°ë˜ëŠ” ë…¸íŠ¸)
        hubs = network_stats['most_linked'][:5]

        # 2. í´ëŸ¬ìŠ¤í„° ë¶„ì„ (íƒœê·¸ ê¸°ë°˜)
        tag_clusters = self._analyze_tag_clusters()

        return {
            **network_stats,
            'hub_notes': hubs,
            'tag_clusters': tag_clusters
        }

    def _analyze_tag_clusters(self) -> List[Dict]:
        """íƒœê·¸ ê¸°ë°˜ í´ëŸ¬ìŠ¤í„° ë¶„ì„"""
        tag_index = self.link_suggester._tag_index

        clusters = []
        for tag, note_paths in tag_index.items():
            if len(note_paths) >= 3:  # 3ê°œ ì´ìƒ ë…¸íŠ¸ê°€ ìˆëŠ” íƒœê·¸ë§Œ
                clusters.append({
                    'tag': tag,
                    'note_count': len(note_paths),
                    'notes': list(note_paths)[:5]  # ìƒìœ„ 5ê°œë§Œ
                })

        # ë…¸íŠ¸ ê°œìˆ˜ìˆœ ì •ë ¬
        return sorted(clusters, key=lambda x: x['note_count'], reverse=True)[:10]

    def _generate_recommendations(
        self,
        statistics: Dict,
        needs_attention: Dict,
        network_insights: Dict
    ) -> List[Dict]:
        """ê°œì„  ì œì•ˆ ìƒì„±"""
        recommendations = []

        # 1. Inbox ì •ë¦¬
        inbox_count = len(needs_attention['unclassified_inbox'])
        if inbox_count >= WEEKLY_REVIEW_CONFIG['inbox_warning_count']:
            recommendations.append({
                'type': 'cleanup_inbox',
                'priority': 'high',
                'message': f'Inboxì— {inbox_count}ê°œ ë…¸íŠ¸ê°€ ìŒ“ì—¬ ìˆìŠµë‹ˆë‹¤',
                'action': '10ë¶„ íˆ¬ìí•´ì„œ ë¶„ë¥˜í•˜ì„¸ìš”',
                'estimated_time': '10ë¶„'
            })

        # 2. ê³ ì•„ ë…¸íŠ¸ ì—°ê²°
        orphan_count = len(needs_attention['orphaned'])
        if orphan_count > 10:
            recommendations.append({
                'type': 'connect_orphans',
                'priority': 'medium',
                'message': f'{orphan_count}ê°œ ê³ ì•„ ë…¸íŠ¸ ë°œê²¬',
                'action': 'ê´€ë ¨ ë…¸íŠ¸ì™€ ë§í¬ ì—°ê²°',
                'affected_notes': needs_attention['orphaned'][:5]
            })

        # 3. ì €í’ˆì§ˆ ë¬¸ì„œ ê°œì„ 
        low_score_count = len(needs_attention['low_score'])
        if low_score_count > 5:
            recommendations.append({
                'type': 'improve_quality',
                'priority': 'low',
                'message': f'{low_score_count}ê°œ ì €í’ˆì§ˆ ë¬¸ì„œ',
                'action': 'ë‚´ìš© ë³´ì™„ ë˜ëŠ” ì‚­ì œ',
                'affected_notes': needs_attention['low_score'][:5]
            })

        # 4. Permanent Note ìƒì„± ê¸°íšŒ
        # (A/S ë“±ê¸‰ í”„ë¡œì íŠ¸ ë…¸íŠ¸ì—ì„œ)
        recommendations.append({
            'type': 'create_permanent_notes',
            'priority': 'medium',
            'message': 'ìš°ìˆ˜ í”„ë¡œì íŠ¸ì—ì„œ ì˜êµ¬ ì§€ì‹ ì¶”ì¶œ',
            'action': 'ì¬ì‚¬ìš© ê°€ëŠ¥í•œ ê°œë…ì„ Zettelkastenìœ¼ë¡œ',
        })

        # 5. ë„¤íŠ¸ì›Œí¬ ê°•í™”
        avg_links = network_insights['avg_links_per_note']
        if avg_links < 2:
            recommendations.append({
                'type': 'strengthen_network',
                'priority': 'medium',
                'message': f'í‰ê·  ë§í¬ ìˆ˜ê°€ ë‚®ìŠµë‹ˆë‹¤ ({avg_links:.1f}ê°œ)',
                'action': 'ê´€ë ¨ ë…¸íŠ¸ë“¤ì„ ë” ì—°ê²°í•˜ì„¸ìš”',
                'target': 'í‰ê·  3ê°œ ì´ìƒ'
            })

        return recommendations

    def save_report(self, report: Dict, output_path: Path = None):
        """ë¦¬í¬íŠ¸ë¥¼ Markdown íŒŒì¼ë¡œ ì €ì¥"""
        if output_path is None:
            # 30-Flow/Weekly/ í´ë”ì— ì €ì¥
            weekly_folder = self.vault_root / FOLDERS['flow'] / 'Weekly'
            weekly_folder.mkdir(parents=True, exist_ok=True)
            output_path = weekly_folder / f"{report['period']}-Review.md"

        content = self._format_report_markdown(report)

        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(content)

        print(f"âœ“ Report saved to: {output_path}")
        return output_path

    def _format_report_markdown(self, report: Dict) -> str:
        """ë¦¬í¬íŠ¸ë¥¼ Markdownìœ¼ë¡œ í¬ë§·"""
        stats = report['statistics']
        needs = report['needs_attention']
        network = report['network_insights']
        recs = report['recommendations']

        md = f"""---
type: weekly-review
period: {report['period']}
generated: {report['generated_at']}
tags: [review, weekly, knowledge-curator]
---

# ğŸ“Š Weekly Knowledge Review: {report['period']}

> **Generated**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
> **System**: Knowledge Curator v1.0.0

---

## ğŸ“ˆ Statistics

**Overall Progress**:
- Total Notes: **{stats['total_notes']}**
- New This Week: **{stats['new_this_week']}**
- Average Score: **{stats['average_score']}/100**

**Grade Distribution**:
"""

        for grade in ['S', 'A', 'B', 'C', 'D']:
            count = stats['grade_distribution'].get(grade, 0)
            pct = (count / stats['total_notes'] * 100) if stats['total_notes'] > 0 else 0
            bar = 'â–ˆ' * int(pct / 5)
            md += f"- {grade}: {count:3d} ({pct:5.1f}%) {bar}\n"

        md += f"\n**Note Type Distribution**:\n"
        for note_type, count in sorted(stats['type_distribution'].items()):
            md += f"- {note_type}: {count}\n"

        md += f"\n---\n\n## ğŸŒŸ Top Documents\n\n"
        for i, doc in enumerate(report['top_documents'][:5], 1):
            md += f"{i}. **[{doc['title']}]({doc['path']})** - {doc['score']}/100 ({doc['grade']})\n"

        md += f"\n---\n\n## âš ï¸  Needs Attention\n\n"

        if needs['low_score']:
            md += f"### ğŸ“‰ Low Quality ({len(needs['low_score'])})\n\n"
            for doc in needs['low_score'][:5]:
                md += f"- [{doc['title']}]({doc['path']}) - {doc['score']}/100\n"

        if needs['orphaned']:
            md += f"\n### ğŸï¸  Orphaned Notes ({len(needs['orphaned'])})\n\n"
            for doc in needs['orphaned'][:5]:
                md += f"- [{doc['title']}]({doc['path']})\n"

        if needs['stale']:
            md += f"\n### ğŸ“… Stale Documents ({len(needs['stale'])})\n\n"
            for doc in needs['stale'][:5]:
                md += f"- [{doc['title']}]({doc['path']}) - {doc['days_old']}ì¼ ë¯¸ìˆ˜ì •\n"

        if needs['unclassified_inbox']:
            md += f"\n### ğŸ“¥ Inbox Backlog ({len(needs['unclassified_inbox'])})\n\n"
            for doc in needs['unclassified_inbox'][:5]:
                md += f"- [{doc['title']}]({doc['path']}) - {doc['days_in_inbox']}ì¼ì§¸\n"

        md += f"\n---\n\n## ğŸ•¸ï¸  Network Insights\n\n"
        md += f"- Total Links: **{network['total_links']}**\n"
        md += f"- Average Links per Note: **{network['avg_links_per_note']}**\n"
        md += f"- Orphaned Notes: **{network['orphaned_notes']}**\n"

        md += f"\n**Hub Notes** (Most Linked):\n"
        for hub in network['hub_notes'][:5]:
            md += f"- [{hub['title']}]({hub['path']}) - {hub['link_count']} links\n"

        if 'tag_clusters' in network and network['tag_clusters']:
            md += f"\n**Tag Clusters**:\n"
            for cluster in network['tag_clusters'][:5]:
                md += f"- #{cluster['tag']}: {cluster['note_count']} notes\n"

        md += f"\n---\n\n## ğŸ’¡ Recommendations\n\n"
        for i, rec in enumerate(recs, 1):
            priority_emoji = {'high': 'ğŸ”´', 'medium': 'ğŸŸ¡', 'low': 'ğŸŸ¢'}
            emoji = priority_emoji.get(rec['priority'], 'âšª')
            md += f"### {i}. {emoji} {rec['message']}\n\n"
            md += f"**Priority**: {rec['priority'].upper()}\n\n"
            md += f"**Action**: {rec['action']}\n\n"

            if 'estimated_time' in rec:
                md += f"**Estimated Time**: {rec['estimated_time']}\n\n"

        md += f"\n---\n\n## ğŸ“ Action Items\n\n"
        md += f"- [ ] Review and address recommendations\n"
        md += f"- [ ] Clean up Inbox\n"
        md += f"- [ ] Connect orphaned notes\n"
        md += f"- [ ] Extract permanent notes from completed projects\n"
        md += f"- [ ] Update stale documents or archive them\n"

        md += f"\n---\n\n*Generated by Knowledge Curator* ğŸ¤–\n"

        return md

    def _get_current_week(self) -> str:
        """í˜„ì¬ ì£¼ì°¨ (YYYY-WXX)"""
        now = datetime.now()
        week_num = now.isocalendar()[1]
        return f"{now.year}-W{week_num:02d}"

    def _is_created_this_week(self, note: MarkdownNote, file_path: Path) -> bool:
        """ì´ë²ˆ ì£¼ì— ìƒì„±ëœ ë…¸íŠ¸ì¸ì§€ í™•ì¸"""
        # Frontmatterì—ì„œ created ë‚ ì§œ í™•ì¸
        created_str = note.frontmatter.get('created') or note.frontmatter.get('imported')

        if created_str:
            try:
                created_date = datetime.fromisoformat(str(created_str).replace('Z', '+00:00'))
                week_ago = datetime.now() - timedelta(days=7)
                return created_date > week_ago
            except:
                pass

        # Frontmatter ì—†ìœ¼ë©´ íŒŒì¼ ìƒì„± ì‹œê°„
        try:
            created_time = datetime.fromtimestamp(file_path.stat().st_ctime)
            week_ago = datetime.now() - timedelta(days=7)
            return created_time > week_ago
        except:
            return False

    def _days_since_modified(self, file_path: Path) -> int:
        """ë§ˆì§€ë§‰ ìˆ˜ì • í›„ ê²½ê³¼ ì¼ìˆ˜"""
        try:
            modified_time = datetime.fromtimestamp(file_path.stat().st_mtime)
            delta = datetime.now() - modified_time
            return delta.days
        except:
            return 0

    def _days_since_created(self, file_path: Path) -> int:
        """ìƒì„± í›„ ê²½ê³¼ ì¼ìˆ˜"""
        try:
            created_time = datetime.fromtimestamp(file_path.stat().st_ctime)
            delta = datetime.now() - created_time
            return delta.days
        except:
            return 0

    def _should_exclude(self, file_path: Path) -> bool:
        """íŒŒì¼ ì œì™¸ ì—¬ë¶€"""
        # automation í´ë”
        if 'automation' in file_path.parts:
            return True

        # ìˆ¨ê¹€ íŒŒì¼/í´ë”
        if any(part.startswith('.') for part in file_path.parts):
            return True

        return False
