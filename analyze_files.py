#!/usr/bin/env python3
"""
Analyze all files in Resources/References to categorize them
"""
import os
from pathlib import Path
import re

def analyze_file(filepath):
    """Analyze a single markdown file"""
    with open(filepath, 'r', encoding='utf-8') as f:
        content = f.read()

    # Remove YAML frontmatter
    content_no_yaml = re.sub(r'^---\n.*?\n---\n', '', content, flags=re.DOTALL)

    # Remove markdown headers and empty lines
    lines = [line.strip() for line in content_no_yaml.split('\n') if line.strip()]

    # Filter out common template text
    template_markers = [
        'ğŸ“ ë‚´ìš©', 'ğŸ·ï¸ ë¶„ë¥˜', 'ğŸ”— ì—°ê²°', 'PARA', 'êµ¬ë¶„',
        'Hub:', 'í™œìš© í”„ë¡œì íŠ¸', 'ê´€ë ¨ ë ˆí¼ëŸ°ìŠ¤', '(ì•„ì§ ì—†ìŒ)',
        'Notionì—ì„œ ì¬ë§ˆì´ê·¸ë ˆì´ì…˜ë¨', '---', '#'
    ]

    real_content_lines = [
        line for line in lines
        if not any(marker in line for marker in template_markers)
        and len(line) > 10  # Ignore very short lines
    ]

    # Calculate metrics
    total_chars = len(content_no_yaml.strip())
    real_content_chars = sum(len(line) for line in real_content_lines)
    num_real_lines = len(real_content_lines)

    return {
        'filename': filepath.name,
        'total_chars': total_chars,
        'real_content_chars': real_content_chars,
        'real_content_lines': num_real_lines,
        'has_substance': real_content_chars > 100 and num_real_lines > 3
    }

def main():
    refs_dir = Path('/Users/qraft_hongjinyoung/DAE-Second-Brain/Resources/References')

    files_analysis = []

    for filepath in sorted(refs_dir.glob('*.md')):
        if filepath.name.startswith('_HUB'):
            continue  # Skip hub files for now

        analysis = analyze_file(filepath)
        files_analysis.append(analysis)

    # Separate substantial from empty files
    substantial = [f for f in files_analysis if f['has_substance']]
    empty = [f for f in files_analysis if not f['has_substance']]

    print(f"ğŸ“Š ë¶„ì„ ê²°ê³¼")
    print(f"=" * 80)
    print(f"ì´ íŒŒì¼ ìˆ˜: {len(files_analysis)}")
    print(f"ë‚´ìš© ìˆëŠ” íŒŒì¼: {len(substantial)}")
    print(f"ë‚´ìš© ë¶€ì‹¤í•œ íŒŒì¼: {len(empty)}")
    print()

    print(f"ğŸ—‘ï¸  ì‚­ì œ í›„ë³´ (ë‚´ìš© ë¶€ì‹¤í•œ íŒŒì¼ {len(empty)}ê°œ)")
    print(f"=" * 80)
    for f in empty:
        print(f"  - {f['filename']:<60} (chars: {f['real_content_chars']}, lines: {f['real_content_lines']})")

    print()
    print(f"âœ… ìœ ì§€í•  íŒŒì¼ ({len(substantial)}ê°œ)")
    print(f"=" * 80)
    for f in substantial[:10]:  # Show first 10
        print(f"  - {f['filename']:<60} (chars: {f['real_content_chars']}, lines: {f['real_content_lines']})")
    print(f"  ... and {len(substantial) - 10} more")

if __name__ == '__main__':
    main()
