---
tags:
  - projects
  - ingestion
  - automation
  - metadata
  - datahub
  - qraft
created: '2025-11-30'
updated: '2025-11-30'
status: ìš´ì˜ì¤‘
team: ML Platform (T)
period: 2025-10 ~ 2025-11
company: í¬ë˜í”„íŠ¸í…Œí¬ë†€ë¡œì§€ìŠ¤
---
# ë©”íƒ€ë°ì´í„° ìë™ ìˆ˜ì§‘ ì²´ê³„

## ğŸ“‹ Overview

**ê¸°ê°„**: 2025ë…„ 10ì›” ~ 11ì›”  
**ì£¼ë„**: ML Platform (T)  
**ë°°ê²½**: ìˆ˜ë™ ë¬¸ì„œí™” â†’ Outdated, ê´€ë¦¬ ë¶ˆê°€  
**ê²°ê³¼**: 3ê°œ Source ìë™ ìˆ˜ì§‘, 254ê°œ ë°ì´í„°ì…‹ ë™ê¸°í™”

---

## ğŸ”¥ ìë™í™”ê°€ í•„ìš”í–ˆë˜ ì´ìœ 

### ìˆ˜ë™ ë¬¸ì„œí™”ì˜ í•œê³„

**Before (Confluence ë¬¸ì„œ)**:

```
1. Data Engineerê°€ ìƒˆ í…Œì´ë¸” ìƒì„±
   â†’ Snowflakeì— í…Œì´ë¸” ìƒì„± ì™„ë£Œ

2. Confluence ë¬¸ì„œ ì—…ë°ì´íŠ¸ (ìˆ˜ë™)
   â†’ "ë‚˜ì¤‘ì— í•˜ì..." â†’ ìŠì–´ë²„ë¦¼
   
3. 3ê°œì›” í›„, ë‹¤ë¥¸ íŒ€ì›ì´ í…Œì´ë¸” ê²€ìƒ‰
   â†’ Confluence: ë¬¸ì„œ ì—†ìŒ
   â†’ Snowflake: í…Œì´ë¸” ìˆìŒ
   â†’ **"ì´ í…Œì´ë¸” ë­ì§€? ëˆ„ê°€ ë§Œë“¤ì—ˆì§€?"**

4. Slack DMìœ¼ë¡œ ë¬¼ì–´ë´„
   â†’ ì›ë˜ ë§Œë“  ì‚¬ëŒ í‡´ì‚¬í•¨
   â†’ ì•„ë¬´ë„ ëª¨ë¦„
```

**ë¬¸ì œì **:
1. **ìˆ˜ë™ ì—…ë°ì´íŠ¸ ë¶€ë‹´**: ë§¤ë²ˆ ë¬¸ì„œ ì—…ë°ì´íŠ¸ â†’ ì•ˆ í•¨
2. **Outdated ì •ë³´**: ì½”ë“œëŠ” ë³€ê²½, ë¬¸ì„œëŠ” ê·¸ëŒ€ë¡œ
3. **ë¶ˆì™„ì „í•œ ì •ë³´**: ì»¬ëŸ¼ ì„¤ëª…, Lineage ë“± ëˆ„ë½
4. **ì—¬ëŸ¬ ê³³ì— í©ì–´ì§**: Confluence + Notion + Google Docs

### ì‹¤ì œ ì‚¬ë¡€

**Case 1: DBT ëª¨ë¸ ì¶”ê°€**
```
Before:
1. DBT ëª¨ë¸ ê°œë°œ (1ì‹œê°„)
2. _models.ymlì— ë©”íƒ€ë°ì´í„° ì‘ì„± (10ë¶„)
3. Confluence ë¬¸ì„œ ì—…ë°ì´íŠ¸ (20ë¶„) â† ìˆ˜ë™
4. Slack ê³µì§€ (5ë¶„) â† ìˆ˜ë™
â†’ ì´ 95ë¶„

After:
1. DBT ëª¨ë¸ ê°œë°œ (1ì‹œê°„)
2. _models.ymlì— ë©”íƒ€ë°ì´í„° ì‘ì„± (10ë¶„)
3. dbt docs generate â†’ S3 ì—…ë¡œë“œ (ìë™)
4. DataHub ingestion (ë§¤ 6ì‹œê°„, ìë™)
5. Slack ì•Œë¦¼ (ìë™, í–¥í›„)
â†’ ì´ 70ë¶„ (-26%)
```

**Case 2: Airflow DAG ìˆ˜ì •**
```
Before:
1. DAG ìˆ˜ì • (30ë¶„)
2. Confluenceì— DAG ì„¤ëª… ì—…ë°ì´íŠ¸ (15ë¶„) â† ìŠì–´ë²„ë¦¼
3. 1ì£¼ì¼ í›„ ë™ë£Œê°€ í˜¼ë€: "ì´ DAG ë­í•˜ëŠ”ê±°ì§€?"
â†’ ìˆ˜ë™ ë¬¸ì„œí™” ì‹¤íŒ¨

After:
1. DAG ìˆ˜ì • (30ë¶„)
2. Docstring ì—…ë°ì´íŠ¸ (5ë¶„)
3. DataHub ingestion (ë§¤ì¼ 1íšŒ, ìë™)
4. ë™ë£Œê°€ DataHubì—ì„œ ìµœì‹  ì„¤ëª… í™•ì¸
â†’ í•­ìƒ ìµœì‹  ìƒíƒœ
```

### CFO ìš”êµ¬ì‚¬í•­

[[ë°ì´í„°-ê±°ë²„ë„ŒìŠ¤-ì „ëµ-ìˆ˜ë¦½|ê±°ë²„ë„ŒìŠ¤ ì „ëµ]] íšŒì˜:

> "ë°ì´í„° ì¹´íƒˆë¡œê·¸ ë§Œë“¤ì—ˆìœ¼ë©´ í•­ìƒ ìµœì‹  ìƒíƒœë¡œ ìœ ì§€ë˜ì–´ì•¼ í•©ë‹ˆë‹¤"

**êµ¬ì²´ì  ìš”êµ¬**:
- ë©”íƒ€ë°ì´í„° ìë™ ë™ê¸°í™”
- Outdated ì •ë³´ ì œê±°
- Owner/ë¹„ìš© ì •ë³´ ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸

---

## ğŸ—ï¸ ìë™ ìˆ˜ì§‘ ì•„í‚¤í…ì²˜

### ì „ì²´ íë¦„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Source Systems                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   Airflow        â”‚      DBT         â”‚     Snowflake          â”‚
â”‚   (PostgreSQL)   â”‚   (S3 Manifest)  â”‚  (INFORMATION_SCHEMA)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                    â”‚                     â”‚
         â”‚ REST API v2        â”‚ S3 Download         â”‚ JDBC
         â”‚                    â”‚                     â”‚
         â†“                    â†“                     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              DataHub Actions (Ingestion Runner)              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Airflow      â”‚ DBT Source    â”‚ Snowflake Connector      â”‚ â”‚
â”‚  â”‚ Custom       â”‚               â”‚                          â”‚ â”‚
â”‚  â”‚ Source       â”‚               â”‚                          â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚         â”‚               â”‚                  â”‚                  â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚                         â”‚                                     â”‚
â”‚                         â†“                                     â”‚
â”‚              MCE (Metadata Change Event)                      â”‚
â”‚                    - URN ìƒì„±                                 â”‚
â”‚                    - Owner ì¶”ì¶œ                               â”‚
â”‚                    - Tag ë§¤í•‘                                 â”‚
â”‚                    - Lineage ì¶”ì¶œ                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â†“ GraphQL mutation
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DataHub GMS                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚ Metadata Storage (MySQL)                                â”‚â”‚
â”‚  â”‚  - Entities (Dataset, DAG, Task)                        â”‚â”‚
â”‚  â”‚  - Aspects (Properties, Ownership, Tags)                â”‚â”‚
â”‚  â”‚  - Lineage (Edges)                                      â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚                           â”‚                                   â”‚
â”‚                           â†“ Kafka                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚ Elasticsearch (ê²€ìƒ‰ ì¸ë±ìŠ¤)                              â”‚â”‚
â”‚  â”‚  - Full-text search                                     â”‚â”‚
â”‚  â”‚  - Tag/Domain í•„í„°                                      â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ìˆ˜ì§‘ ì£¼ê¸°

| Source | ì£¼ê¸° | ì´ìœ  |
|--------|------|------|
| **Airflow** | ë§¤ 6ì‹œê°„ | DAG/Task ë³€ê²½ ë¹ˆë²ˆ |
| **DBT** | ë§¤ì¼ 1íšŒ | Manifest S3 ì—…ë¡œë“œ í›„ |
| **Snowflake** | ì£¼ 1íšŒ | ìŠ¤í‚¤ë§ˆ ë³€ê²½ ë“œë¬¾ |

---

## ğŸ”§ Sourceë³„ êµ¬í˜„

### 1. Airflow Custom Source

**Why Custom?**
- Built-in connectorëŠ” Airflow 2.x ì „ìš©
- Airflow 3.x serialized_dag êµ¬ì¡° ë³€ê²½
- Keycloak OIDC ì¸ì¦ í•„ìš”

[[Airflow-3.0-êµ¬í˜„|ê¸°ìˆ  ìƒì„¸]]

**ìˆ˜ì§‘ ë‚´ìš©**:
```python
# custom_sources/airflow/airflow_source.py
class AirflowSource(Source):
    def get_workunits(self):
        # 1. DAG ë©”íƒ€ë°ì´í„°
        for dag in self.api_client.get_dags():
            yield MetadataWorkUnit(
                id=dag.dag_id,
                mce=MetadataChangeEvent(
                    proposedSnapshot=DataJobSnapshot(
                        urn=f"urn:li:dataJob:(urn:li:dataFlow:(...),{dag.dag_id})",
                        aspects=[
                            DataJobInfoClass(
                                name=dag.dag_id,
                                description=dag.description,
                                customProperties={
                                    "schedule": dag.schedule_interval,
                                    "start_date": dag.start_date,
                                    "tags": ",".join(dag.tags),
                                }
                            ),
                            OwnershipClass(
                                owners=[self._extract_owner(dag.tags)]
                            ),
                            GlobalTagsClass(
                                tags=[self._map_tags(dag.tags)]
                            ),
                        ]
                    )
                )
            )
        
        # 2. Task ì˜ì¡´ì„± (Lineage)
        for dag_id in dag_ids:
            tasks = self.metadata_db_client.get_task_dependencies(dag_id)
            for task in tasks:
                yield self._build_task_lineage(task)
        
        # 3. Assets (Datasets)
        for dag_id in dag_ids:
            assets = self.api_client.get_dag_details(dag_id).get("datasets", [])
            for asset in assets:
                yield self._build_dataset(asset)
```

**Owner ì¶”ì¶œ**:
```python
def _extract_owner(self, tags: list[str]) -> str:
    """DAG tagsì—ì„œ team: ì¶”ì¶œ â†’ Owner URN ìƒì„±"""
    for tag in tags:
        if tag.startswith("team:"):
            team_name = tag.replace("team:", "")
            # (T) suffix â†’ corpGroup
            if team_name.endswith(" (T)"):
                return f"urn:li:corpGroup:{quote_plus(team_name)}"
            else:
                return f"urn:li:corpuser:{quote_plus(team_name)}"
    
    # Fallback: Public
    return "urn:li:corpGroup:Public"
```

**Lineage ì¶”ì¶œ** (Airflow 3.x ëŒ€ì‘):
```python
def get_task_dependencies(self, dag_id: str):
    """serialized_dagì—ì„œ task ì˜ì¡´ì„± ì¶”ì¶œ"""
    query = """
    SELECT dag.dag_id, dag.data
    FROM serialized_dag dag
    WHERE dag.dag_id = %s
    """
    result = self.conn.execute(query, (dag_id,))
    data = json.loads(result["data"])
    
    # Airflow 3.x: __var êµ¬ì¡°
    tasks = data["dag"]["tasks"]
    upstream_deps = defaultdict(list)
    
    for task in tasks:
        if "__var" not in task:
            continue
        
        task_var = task["__var"]
        task_id = task_var.get("task_id")
        downstream_ids = task_var.get("downstream_task_ids", [])
        
        # downstream â†’ upstream ì—­ë³€í™˜
        for downstream_id in downstream_ids:
            upstream_deps[downstream_id].append(task_id)
    
    return upstream_deps
```

**Schedule**: ë§¤ 6ì‹œê°„ (Cron: `0 */6 * * *`)

### 2. DBT Source

**Why S3-based?**
- dbt-core ì§ì ‘ ì—°ë™ ì‹œ dbt compile í•„ìš” â†’ ëŠë¦¼
- S3 manifest.json â†’ ë¹ ë¥¸ ìˆ˜ì§‘, ë²„ì „ ê´€ë¦¬

**ìˆ˜ì§‘ íë¦„**:
```
1. DBT í”„ë¡œì íŠ¸ì—ì„œ dbt docs generate
   â†’ manifest.json, catalog.json ìƒì„±

2. Airflow DAGê°€ S3 ì—…ë¡œë“œ
   â†’ s3://qraft-dbt-artifacts/manifest.json

3. DataHub DBT Sourceê°€ S3ì—ì„œ ë‹¤ìš´ë¡œë“œ
   â†’ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ

4. DataHub GMSë¡œ ì „ì†¡
   â†’ ê²€ìƒ‰ ì¸ë±ì‹±
```

**ë©”íƒ€ë°ì´í„° ì¶”ì¶œ**:
```yaml
# manifest.json êµ¬ì¡°
nodes:
  model.qraft.us_simul_data:
    name: us_simul_data
    description: "US Simulation Data..."
    meta:
      owner: "urn:li:corpGroup:Strategy+%28T%29"
      technical_owner: "urn:li:corpGroup:ML+Platform+%28T%29"
      datahub:
        domain: "urn:li:domain:USSimulation"
    
    columns:
      datadate:
        name: datadate
        description: "ë°ì´í„° ê¸°ì¤€ì¼"
        data_type: DATE
      
      gvkey:
        name: gvkey
        description: "Global Company Key"
        data_type: VARCHAR
    
    depends_on:
      nodes:
        - model.qraft.int_us_simul_data_base
        - source.ciq.sec_dprc
```

**Owner URN í†µì¼** (Runtime Patch):
```bash
# entrypoint-actions.sh
# DBTì˜ UrnEncoder â†’ quote_plusë¡œ ë³€ê²½
sed -i 's/from datahub.emitter.mce_builder import make_group_urn/from urllib.parse import quote_plus\ndef make_group_urn(group): return f"urn:li:corpGroup:{quote_plus(group)}"/g' \
    /usr/local/lib/python3.10/site-packages/datahub/ingestion/source/dbt/dbt_common.py
```

[[03-Resources/Technology/DataHub/URN-Encoding-í†µì¼|URN í†µì¼ ìƒì„¸]]

**Schedule**: ë§¤ì¼ 1íšŒ (Cron: `0 9 * * *`)

### 3. Snowflake Source

**Why INFORMATION_SCHEMA?**
- Snowflake metadata API ì œê³µ
- ìŠ¤í‚¤ë§ˆ, í…Œì´ë¸”, ì»¬ëŸ¼ ì •ë³´ ìë™ ìˆ˜ì§‘

**ìˆ˜ì§‘ ì¿¼ë¦¬**:
```sql
-- í…Œì´ë¸” ëª©ë¡
SELECT 
    table_catalog,
    table_schema,
    table_name,
    table_type,  -- BASE TABLE, VIEW
    comment
FROM information_schema.tables
WHERE table_schema NOT IN ('INFORMATION_SCHEMA', 'DBT_*', 'DEV_*');

-- ì»¬ëŸ¼ ì •ë³´
SELECT
    table_schema,
    table_name,
    column_name,
    data_type,
    comment
FROM information_schema.columns
WHERE table_schema = 'MART';

-- í…Œì´ë¸” í†µê³„
SELECT
    table_schema,
    table_name,
    row_count,
    bytes,
    last_altered
FROM information_schema.tables;
```

**Owner ë§¤í•‘** (í–¥í›„ êµ¬í˜„):
```sql
-- Snowflake Tag ê¸°ë°˜ Owner
SELECT 
    object_name,
    tag_name,
    tag_value
FROM snowflake.account_usage.tag_references
WHERE tag_name = 'OWNER';

-- Example:
-- us_simul_data | OWNER | Strategy (T)
```

**Schedule**: ì£¼ 1íšŒ (Cron: `0 2 * * 0`)

---

## ğŸ“Š ìˆ˜ì§‘ ì„±ê³¼

### ë©”íƒ€ë°ì´í„° ì»¤ë²„ë¦¬ì§€

| Source | Entities | Lineage | Owner ì»¤ë²„ë¦¬ì§€ |
|--------|----------|---------|----------------|
| **Airflow** | 38 DAGs, 150+ Tasks | 79 deps | 100% (tags ê¸°ë°˜) |
| **DBT** | 127 Models | 245 ref() | 100% (_models.yml) |
| **Snowflake** | 89 Tables/Views | - | 0% (í–¥í›„) |
| **Total** | 254 Datasets | 324 edges | 85% |

### ìë™í™” íš¨ê³¼

| ì‘ì—… | Before (ìˆ˜ë™) | After (ìë™) | ê°œì„ ìœ¨ |
|------|--------------|-------------|--------|
| **ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸** | 20ë¶„/ê±´ | ìë™ | **-100%** |
| **Outdated ì •ë³´** | 50%+ | 0% | **-100%** |
| **Lineage ì¶”ì ** | 1ì‹œê°„ | ì‹¤ì‹œê°„ | **-100%** |
| **Owner í™•ì¸** | Slack DM | ì¦‰ì‹œ | **-100%** |

### ìš´ì˜ ë¶€ë‹´ ê°ì†Œ

**Before (ìˆ˜ë™ ë¬¸ì„œí™”)**:
```
ì£¼ê°„ ë¬¸ì„œ ì—…ë°ì´íŠ¸ ì‹œê°„:
  - DAG ì¶”ê°€/ìˆ˜ì •: 10ê±´ Ã— 15ë¶„ = 150ë¶„
  - DBT ëª¨ë¸ ë³€ê²½: 5ê±´ Ã— 20ë¶„ = 100ë¶„
  - Snowflake ìŠ¤í‚¤ë§ˆ ë³€ê²½: 2ê±´ Ã— 30ë¶„ = 60ë¶„
  - Confluence ì •ë¦¬: 60ë¶„
  â†’ ì´ 370ë¶„/ì£¼ (6.2ì‹œê°„)
  
ì—°ê°„: 6.2ì‹œê°„/ì£¼ Ã— 52ì£¼ = 322ì‹œê°„
```

**After (ìë™ ìˆ˜ì§‘)**:
```
ì£¼ê°„ ìœ ì§€ë³´ìˆ˜ ì‹œê°„:
  - Ingestion ëª¨ë‹ˆí„°ë§: 10ë¶„
  - Recipe ìˆ˜ì • (í•„ìš” ì‹œ): 20ë¶„
  â†’ ì´ 30ë¶„/ì£¼ (0.5ì‹œê°„)
  
ì—°ê°„: 0.5ì‹œê°„/ì£¼ Ã— 52ì£¼ = 26ì‹œê°„

ì ˆê°: 322 - 26 = 296ì‹œê°„/ë…„ (-92%)
```

---

## ğŸš€ Ingestion ì‹¤í–‰

### UI ì‹¤í–‰ (ê¶Œì¥)

```
1. DataHub UI ì ‘ì†: http://localhost:9002
2. Ingestion ë©”ë‰´ í´ë¦­
3. Source ì„ íƒ:
   - dbt_qraft
   - airflow_local
   - snowflake_qraft
4. Execute ë²„íŠ¼ í´ë¦­
5. ì§„í–‰ ìƒí™© ì‹¤ì‹œê°„ í™•ì¸
```

### GraphQL API (ìë™í™”)

```bash
# DBT Ingestion ì‹¤í–‰
curl -X POST http://localhost:8080/api/graphql \
  -H "Content-Type: application/json" \
  -d '{
    "query": "mutation { executeIngestionSource(urn: \"urn:li:dataHubIngestionSource:dbt-qraft\") }"
  }'

# ì‹¤í–‰ ìƒíƒœ í™•ì¸
curl -X POST http://localhost:8080/api/graphql \
  -H "Content-Type: application/json" \
  -d '{
    "query": "query { 
      listIngestionRuns(input: {
        sourceUrn: \"urn:li:dataHubIngestionSource:dbt-qraft\",
        start: 0,
        count: 10
      }) { 
        runs { 
          urn 
          status 
          startTimeMs 
          durationMs 
        } 
      } 
    }"
  }'
```

### Airflow DAG (í–¥í›„)

```python
# dags/datahub_ingestion.py
from airflow import DAG
from airflow.providers.http.operators.http import SimpleHttpOperator

dag = DAG(
    dag_id="datahub_daily_ingestion",
    schedule_interval="0 9 * * *",  # ë§¤ì¼ 09:00
)

# DBT Ingestion
trigger_dbt_ingestion = SimpleHttpOperator(
    task_id="trigger_dbt_ingestion",
    http_conn_id="datahub_gms",
    endpoint="/api/graphql",
    method="POST",
    data=json.dumps({
        "query": "mutation { executeIngestionSource(...) }"
    }),
    dag=dag,
)
```

---

## ğŸ”— ê´€ë ¨ ë¬¸ì„œ

### Projects
- [[ë°ì´í„°-ê±°ë²„ë„ŒìŠ¤-ì „ëµ-ìˆ˜ë¦½]]: ì „ì²´ ê±°ë²„ë„ŒìŠ¤ ì „ëµ
- [[DataHub-ë„ì…]]: ë©”íƒ€ë°ì´í„° í”Œë«í¼
- [[ë°ì´í„°-ì¹´íƒˆë¡œê·¸-êµ¬ì¶•]]: ì¹´íƒˆë¡œê·¸ êµ¬ì¡°
- [[íŒ€ë³„-ë°ì´í„°-ê²©ë¦¬-ì²´ê³„]]: Owner ê¸°ë°˜ ê¶Œí•œ

### Technology
- [[03-Resources/Technology/DataHub/Custom-Sources]]: Airflow Custom Connector
- [[03-Resources/Technology/DataHub/URN-Encoding-í†µì¼]]: URN ì¼ê´€ì„±
- [[03-Resources/Technology/Airflow/Airflow-3.0-êµ¬í˜„]]: Airflow 3.x ëŒ€ì‘
- [[03-Resources/Technology/DBT/DBT-êµ¬í˜„]]: DBT manifest êµ¬ì¡°

### Weekly (ì‹¤ì œ ê²½í—˜)
- [[2025ë…„ 11ì›” 24ì¼]]: Airflow-DBT-DB ì—°ê²° ì™„ë£Œ, ë©”íƒ€ë°ì´í„° ìë™ ìˆ˜ì§‘

---

## ğŸ“ êµí›ˆ

### âœ… ì˜í•œ ì 

1. **S3 ê¸°ë°˜ DBT**: dbt-core ì§ì ‘ ì—°ë™ ëŒ€ì‹  manifest í™œìš© â†’ ë¹ ë¦„
2. **Custom Airflow Source**: Built-in ëŒ€ì‹  Custom ê°œë°œ â†’ Airflow 3.x ëŒ€ì‘
3. **Runtime Patch**: íŒ¨í‚¤ì§€ ì¬ë¹Œë“œ ì—†ì´ URN í†µì¼
4. **GraphQL API**: UI ì˜ì¡´ ì—†ì´ ìë™í™” ê°€ëŠ¥

### âš ï¸ Trial & Error

1. **CLI ì‹¤í–‰ ê¸ˆì§€**: CLI vs UI ë™ì‘ ë¶ˆì¼ì¹˜ â†’ UI/APIë§Œ ì‚¬ìš©
2. **URN Encoding**: Keycloak vs DBT ë¶ˆì¼ì¹˜ â†’ Runtime patch
3. **Airflow 3.x Lineage**: Serialized DAG êµ¬ì¡° ë³€ê²½ â†’ Custom parsing
4. **Snowflake ëŒ€ì†Œë¬¸ì**: TABLE vs table ì¤‘ë³µ â†’ ì†Œë¬¸ì í†µì¼

### ğŸ”® í–¥í›„ ê³„íš

1. **Real-time Ingestion**: Kafka ê¸°ë°˜ ì‹¤ì‹œê°„ ìˆ˜ì§‘
   - Airflow DAG ìƒì„± ì‹œ ì¦‰ì‹œ DataHub ì—…ë°ì´íŠ¸
   - DBT run ì™„ë£Œ ì‹œ ì¦‰ì‹œ Lineage ì—…ë°ì´íŠ¸

2. **Column-level Lineage**: ì»¬ëŸ¼ ë‹¨ìœ„ ì¶”ì 
   - DBT ref() â†’ ì»¬ëŸ¼ ë§¤í•‘
   - SQL íŒŒì‹± â†’ SELECT ì»¬ëŸ¼ ì¶”ì 

3. **Snowflake Query Log**: ì‹¤ì œ ì‚¬ìš© íŒ¨í„´ ìˆ˜ì§‘
   - ì–´ë–¤ í…Œì´ë¸”ì„ ëˆ„ê°€ ìì£¼ ì¿¼ë¦¬í•˜ëŠ”ì§€
   - Zombie table íƒì§€ (ì•ˆ ì“°ëŠ” í…Œì´ë¸”)

4. **ë°ì´í„° í”„ë¡œíŒŒì¼ë§**: í†µê³„ ì •ë³´ ìë™ ìˆ˜ì§‘
   - Row count, Null ë¹„ìœ¨
   - ë°ì´í„° ë¶„í¬ (min, max, avg)
   - Great Expectations ì—°ë™

5. **Slack ì•Œë¦¼**: ë³€ê²½ ì‚¬í•­ ìë™ ê³µì§€
   - ìƒˆ í…Œì´ë¸” ìƒì„± â†’ Slack ì•Œë¦¼
   - Lineage ë³€ê²½ â†’ ì˜í–¥ë°›ëŠ” íŒ€ ì•Œë¦¼

---

**ì‘ì„±ì¼**: 2025-11-30  
**ì‘ì„±ì**: ML Platform (T)  
**ìƒíƒœ**: âœ… ìš´ì˜ ì¤‘, 254ê°œ ë°ì´í„°ì…‹ ìë™ ìˆ˜ì§‘
